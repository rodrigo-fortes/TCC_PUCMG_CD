{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodrigo-fortes/TCC_PUCMG_CD/blob/main/TCC_PUCMG_CUSTEIO_RURAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6vzW_X9TfQi"
      },
      "source": [
        "# **Pontifícia Universidade Católica de Minas Gerais - PUC-MG**\n",
        "# Especialização em Ciência da Dados e Big Data\n",
        "# Códigos Referentes ao Trabalho de Conclusão de Curso\n",
        "\n",
        "## **ANÁLISE DE PREVISIBILIDADE DE CUSTEIO RURAL POR PRODUTO PARA MUNICÍPIOS DO ESTADO DE MINAS GERAIS**\n",
        "\n",
        "## Aluno: Rodrigo Fortes Lopes\n",
        "\n",
        ".\n",
        ".\n",
        "\n",
        "**Fontes dos dados:**\n",
        "\n",
        "\n",
        "Bacen - Matriz de Dados do Crédito Rural - MDCR\n",
        "Dados agregados relativos a operações de crédito rural registradas no sistema Sicor, contratadas por produtores rurais em instituições financeiras.\n",
        "\n",
        "https://dadosabertos.bcb.gov.br/dataset/matrizdadoscreditorural\n",
        "\n",
        "https://dadosabertos.bcb.gov.br/dataset/matrizdadoscreditorural/resource/5e70f0f7-61ea-4c39-b7ed-2dae9166bdca\n",
        "\n",
        ".\n",
        ".\n",
        "\n",
        "DTB - Divisão Territorial Brasileira\n",
        "\n",
        "https://www.ibge.gov.br/geociencias/organizacao-do-territorio/estrutura-territorial/23701-divisao-territorial-brasileira.html\n",
        "\n",
        ".\n",
        ".\n",
        "\n",
        "Códigos dos municípios IBGE\n",
        "\n",
        "https://www.ibge.gov.br/explica/codigos-dos-municipios.php\n",
        "\n",
        ".\n",
        ".\n",
        "\n",
        "Áreas Territoriais\n",
        "\n",
        "https://www.ibge.gov.br/geociencias/organizacao-do-territorio/estrutura-territorial/15761-areas-dos-municipios.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc4y-OMOhsDS"
      },
      "source": [
        "## Conexões e pacotes texto em itálico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzSmgjq-TVmz",
        "outputId": "14b14fe7-f967-4727-975c-5170219d3126"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Acesso ao Google Drive que contém o material de estudo\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K82WgOqzTcNQ"
      },
      "outputs": [],
      "source": [
        "# Pacotes para análises e gráficos\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXqmv14LWgg_"
      },
      "source": [
        "## Carga dos dados e Identificação das Colunas\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ss-6bW6HTcQq"
      },
      "outputs": [],
      "source": [
        "# Arquivos CSV\n",
        "\n",
        "custeio = pd.read_csv('/content/drive/MyDrive/PUC Minas - Ciência de Dados e Big Data/17 - TCC - CIÊNCIA DE DADOS E BIG DATA/Credito_Rural/05_Contratos_de_Custeio_por_Municipio_e_Produto/Custeio.csv',\n",
        "                 sep = ',', encoding = 'utf-8',engine='c')\n",
        "\n",
        "ibge = pd.read_csv('/content/drive/MyDrive/PUC Minas - Ciência de Dados e Big Data/17 - TCC - CIÊNCIA DE DADOS E BIG DATA/Credito_Rural/21_Microrregioes_IBGE/RELATORIO_DTB_BRASIL_MUNICIPIO_v2.csv',\n",
        "                 sep = ',', encoding = 'utf-8',engine='c')\n",
        "\n",
        "area = pd.read_csv('/content/drive/MyDrive/PUC Minas - Ciência de Dados e Big Data/17 - TCC - CIÊNCIA DE DADOS E BIG DATA/Credito_Rural/21_Microrregioes_IBGE/area_municipios.csv',\n",
        "                 sep = ',', encoding = 'utf-8',engine='c')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFaIDiVcaz3Q"
      },
      "outputs": [],
      "source": [
        "# Colunas de custeio\n",
        "custeio.info(verbose=True, null_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSHLhPrcco5p"
      },
      "outputs": [],
      "source": [
        "# Primeiras linhas da base custeio\n",
        "custeio.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4orGqcQa0G0"
      },
      "outputs": [],
      "source": [
        "# Colunas de ibge\n",
        "ibge.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlGFb0B0c8d9"
      },
      "outputs": [],
      "source": [
        "# Primeiras linhas da base igbe\n",
        "ibge.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5NOK5F2a0W6"
      },
      "outputs": [],
      "source": [
        "# Colunas de area\n",
        "area.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3aAyqSw0fTdy"
      },
      "outputs": [],
      "source": [
        "# Primeiras linhas da base area\n",
        "area.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PESdPWAwWtzL"
      },
      "source": [
        "## Ajustes dos dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQeSXZqAWX6K"
      },
      "outputs": [],
      "source": [
        "# Trocar \",\" por \".\" na coluna de Valor de Custeio\n",
        "\n",
        "custeio['VlCusteio'] = custeio['VlCusteio'].replace({',': '.'}, regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkdUIW_HWX9h"
      },
      "outputs": [],
      "source": [
        "# Converte para número o AnoEmissao, MesEmissao, VlCusteio\n",
        "\n",
        "custeio['AnoEmissao'] = pd.to_numeric(custeio['AnoEmissao'], errors='coerce')\n",
        "custeio['MesEmissao'] = pd.to_numeric(custeio['MesEmissao'], errors='coerce')\n",
        "custeio['VlCusteio'] = pd.to_numeric(custeio['VlCusteio'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLcWh31YWX_8"
      },
      "outputs": [],
      "source": [
        "# Modifica os nomes das colunas de Códigos Municipais para que fiquem iguais e permitam fazer o merge das tabelas\n",
        "\n",
        "ibge.rename(columns={'Código Município Completo': 'codIbge'}, inplace = True)\n",
        "area.rename(columns={'CD_MUN': 'codIbge'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXFNwseAWYCn"
      },
      "outputs": [],
      "source": [
        "# Ajustes no campo de área municipal\n",
        "\n",
        "area['AR_MUN_2022'] = area['AR_MUN_2022'].replace({',': '.'}, regex=True)\n",
        "area['AR_MUN_2022'] = pd.to_numeric(area['AR_MUN_2022'], errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khczRtncpfuS"
      },
      "source": [
        "## Análise e Exploração dos Dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V29s8HIZp-zp"
      },
      "outputs": [],
      "source": [
        "# Cópia da Base\n",
        "\n",
        "custeio_ae = custeio.copy()\n",
        "ibge_ae = ibge.copy()\n",
        "area_ae = area.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xH938Zt7q6Fe"
      },
      "outputs": [],
      "source": [
        "custeio_ae.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shzQw8MoOblq"
      },
      "outputs": [],
      "source": [
        "len(custeio_ae['nomeProduto'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b7B12F2rAmM"
      },
      "outputs": [],
      "source": [
        "custeio_ae.info(verbose=True, null_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbCrl24ArAwo"
      },
      "outputs": [],
      "source": [
        "custeio_ae = custeio_ae[custeio_ae.cdEstado.isin([12])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nboHMHAxrA12"
      },
      "outputs": [],
      "source": [
        "custeio_ae.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10V4XB-PrBCg"
      },
      "outputs": [],
      "source": [
        "len(custeio_ae['nomeProduto'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SnWzHG3SUeO"
      },
      "outputs": [],
      "source": [
        "# Atividade (contagem)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,5))\n",
        "sns.countplot(data=custeio_ae, x=\"AnoEmissao\", hue=\"Atividade\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n686Sc7HTjtB"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(12, 5))\n",
        "sns.barplot(data=custeio_ae, x=\"AnoEmissao\", y=\"VlCusteio\", hue=\"Atividade\", estimator=sum)\n",
        "\n",
        "ax.set_xlabel(\"Ano de Emissão\")\n",
        "ax.set_ylabel(\"Valor de Custeio\")\n",
        "ax.set_title(\"Soma do Valor de Custeio por Ano e Atividade\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vb5vTtIrBHV"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8,6))\n",
        "sns.scatterplot(data=custeio_ae, x = 'AnoEmissao', y = 'VlCusteio')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQerkr_fxB-b"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "sns.boxplot(data=custeio_ae, x = 'AnoEmissao', y = 'VlCusteio')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZUCzz4wyDwJ"
      },
      "outputs": [],
      "source": [
        "a = custeio_ae['nomeProduto'].value_counts(normalize=True)\n",
        "a = pd.DataFrame(a)\n",
        "a.head(11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23c6OECRfdYV"
      },
      "outputs": [],
      "source": [
        "# Filtrar os \"nomeProduto\" que existem em todos os \"AnoEmissao\"\n",
        "produto_anos = custeio_ae.groupby('nomeProduto')['AnoEmissao'].nunique()\n",
        "nome_produto_todos_anos = produto_anos[produto_anos == produto_anos.max()].index\n",
        "\n",
        "# Filtrar os registros apenas para os \"nomeProduto\" desejados\n",
        "data_filtrada = custeio_ae[custeio_ae['nomeProduto'].isin(nome_produto_todos_anos)]\n",
        "\n",
        "# Calcular a soma total de \"VlCusteio\" para cada \"nomeProduto\"\n",
        "soma_custeio_por_produto = data_filtrada.groupby('nomeProduto')['VlCusteio'].sum()\n",
        "\n",
        "# Identificar os 10 \"nomeProduto\" com a maior soma de \"VlCusteio\"\n",
        "top_10_produtos = soma_custeio_por_produto.nlargest(10)\n",
        "\n",
        "print(\"Os 10 maiores nomeProduto em soma de VlCusteio:\")\n",
        "print(top_10_produtos)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hve4iMd1yT9y"
      },
      "outputs": [],
      "source": [
        "# Seleção dos 10 produtos com maior soma de VlCusteio e que aparecem em todos os anos da série\n",
        "selec10 = ['\"BOVINOS\"', '\"CAFÉ\"', '\"SOJA\"', '\"MILHO\"', '\"CANA-DE-AÇUCAR\"',\n",
        "           '\"SUÍNOS\"', '\"ALHO\"', '\"BATATA-INGLESA\"', '\"FEIJÃO\"', '\"BANANA\"']\n",
        "\n",
        "# Calcular a soma total de \"VlCusteio\" para cada \"nomeProduto\"\n",
        "soma_custeio_por_produto = custeio_ae.groupby('nomeProduto')['VlCusteio'].sum().reset_index()\n",
        "\n",
        "# Filtrar os produtos desejados\n",
        "df_soma = soma_custeio_por_produto[soma_custeio_por_produto['nomeProduto'].isin(selec10)]\n",
        "\n",
        "# Ordenar em ordem decrescente de soma de VlCusteio\n",
        "df_soma = df_soma.sort_values('VlCusteio', ascending=False)\n",
        "\n",
        "# Criar um gráfico de barras para visualizar a soma de VlCusteio por nomeProduto (apenas os 10 maiores)\n",
        "plt.barh(df_soma['nomeProduto'], df_soma['VlCusteio'])\n",
        "plt.xlabel('Soma de VlCusteio')\n",
        "plt.ylabel('nomeProduto')\n",
        "plt.title('Soma de VlCusteio por nomeProduto (10 maiores)')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q6r6FAqyD3m"
      },
      "outputs": [],
      "source": [
        "# Merge com IBGE\n",
        "ibge_ae.rename(columns={'Código Município Completo': 'codIbge'}, inplace = True)\n",
        "\n",
        "custeio_meso = pd.merge(custeio_ae, ibge_ae, how = 'left')\n",
        "custeio_meso.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5O-2uDNaPvP"
      },
      "outputs": [],
      "source": [
        "custeio_meso['Nome_Mesorregião'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG_lrXjtaQCt"
      },
      "outputs": [],
      "source": [
        "len(custeio_meso['Nome_Mesorregião'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7addi3UL7yz"
      },
      "outputs": [],
      "source": [
        "# Calcular a soma de VlCusteio por mesorregião\n",
        "df_sum_mesorregiao = custeio_meso.groupby('Nome_Mesorregião')['VlCusteio'].sum()\n",
        "\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "# Calcular a participação percentual\n",
        "df_percentual = df_sum_mesorregiao / df_sum_mesorregiao.sum() * 100\n",
        "\n",
        "# Ordenar os valores em ordem decrescente\n",
        "df_percentual = df_percentual.sort_values(ascending=False)\n",
        "\n",
        "# Gerar um gráfico de pizza\n",
        "plt.figure(figsize=(10, 10))\n",
        "df_percentual.plot(kind='pie', autopct='%1.1f%%')\n",
        "plt.ylabel('')\n",
        "plt.title('Participação Percentual de VlCusteio por Mesorregião')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XutgcnWIIui_"
      },
      "outputs": [],
      "source": [
        "# Calcular a soma de VlCusteio por Mesorregião e nomeProduto\n",
        "df_grouped = custeio_meso.groupby(['Nome_Mesorregião', 'nomeProduto'])['VlCusteio'].sum().reset_index()\n",
        "\n",
        "top10_nomeProduto_por_mesorregiao = (df_grouped.groupby('Nome_Mesorregião').apply(lambda x: x.nlargest(10,\n",
        "                                                                    'VlCusteio')).reset_index(drop=True))\n",
        "\n",
        "# Criar um gráfico para cada Mesorregião\n",
        "for mesorregiao in top10_nomeProduto_por_mesorregiao['Nome_Mesorregião'].unique():\n",
        "    df_mesorregiao = top10_nomeProduto_por_mesorregiao[top10_nomeProduto_por_mesorregiao['Nome_Mesorregião'] == mesorregiao]\n",
        "    plt.figure(figsize=(10, 6))  # Ajuste o tamanho do gráfico conforme necessário\n",
        "    ax = sns.barplot(data=df_mesorregiao, y='nomeProduto', x='VlCusteio', color='skyblue', orient='horizontal')\n",
        "    plt.xlabel('Soma de VlCusteio')\n",
        "    plt.ylabel('Nome do Produto')\n",
        "    plt.title(f'Soma de VlCusteio por nomeProduto - Mesorregião: {mesorregiao}')\n",
        "    plt.tight_layout()  # Para melhorar a visualização dos rótulos\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFtth3gOUx6M"
      },
      "outputs": [],
      "source": [
        "# Agrupar por nomeProduto e Nome_Mesorregião e calcular a média de VlCusteio por Município por Ano\n",
        "df_grouped = custeio_meso.groupby(['nomeProduto','AnoEmissao', 'Municipio','Nome_Mesorregião'])['VlCusteio'].sum().reset_index()\n",
        "df_grouped = df_grouped.groupby(['nomeProduto','Nome_Mesorregião'])['VlCusteio'].mean().reset_index()\n",
        "\n",
        "# Obter a lista de nomeProduto\n",
        "produtos = df_grouped['nomeProduto'].unique()\n",
        "\n",
        "# Criar um gráfico para cada nomeProduto\n",
        "for produto in produtos:\n",
        "    # Filtrar os dados para o nomeProduto atual\n",
        "    df_produto = df_grouped[df_grouped['nomeProduto'] == produto]\n",
        "\n",
        "    # Ordenar os dados por soma de VlCusteio em ordem decrescente\n",
        "    df_produto = df_produto.sort_values(by='VlCusteio', ascending=False)\n",
        "\n",
        "    # Criar o gráfico de barras horizontais\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(df_produto['Nome_Mesorregião'], df_produto['VlCusteio'], color='skyblue')\n",
        "\n",
        "    # Configurar os rótulos e título do gráfico\n",
        "    plt.xlabel('Média de Valor de Custeio')\n",
        "    plt.ylabel('Nome da Mesorregião')\n",
        "    plt.title(f'Média de VlCusteio por Nome_Mesorregião - nomeProduto: {produto}')\n",
        "\n",
        "    # Inverter a ordem do eixo y para exibir as barras na ordem correta\n",
        "    plt.gca().invert_yaxis()\n",
        "\n",
        "    # Exibir o gráfico\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bM0g7DMGrBRl"
      },
      "outputs": [],
      "source": [
        "area_ae.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDhtG8o9q6Tu"
      },
      "outputs": [],
      "source": [
        "# Histograma das áreas municipais de MG\n",
        "\n",
        "# Filtrar os dados para CD_UF = 12\n",
        "dados_filtrados = area_ae[area_ae[\"CD_UF\"] == 12]\n",
        "\n",
        "# Gerar o histograma\n",
        "plt.hist(dados_filtrados[\"AR_MUN_2022\"], bins=20)\n",
        "plt.xlabel(\"Área Municipal (2022)\")\n",
        "plt.ylabel(\"Frequência\")\n",
        "plt.title(\"Histograma da Área Municipal (2022) para CD_UF = 12\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dKCBW0hlV9p"
      },
      "outputs": [],
      "source": [
        "# Calcular os quartis\n",
        "quartis = dados_filtrados[\"AR_MUN_2022\"].quantile([0.25, 0.5, 0.75])\n",
        "\n",
        "print(\"Q1:\", quartis[0.25])\n",
        "print(\"Q2 (Mediana):\", quartis[0.5])\n",
        "print(\"Q3:\", quartis[0.75])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvyKbLhgphhS"
      },
      "outputs": [],
      "source": [
        "# Merge com area_ae\n",
        "\n",
        "custeio_meso2 = pd.merge(custeio_meso, area_ae, how = 'left')\n",
        "custeio_meso3 = custeio_meso2[['Municipio', 'Nome_Mesorregião', 'nomeProduto',\n",
        "                               'MesEmissao', 'AnoEmissao', 'cdEstado', 'VlCusteio', 'AR_MUN_2022']]\n",
        "custeio_meso3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBU4fdsjphlT"
      },
      "outputs": [],
      "source": [
        "custeio_meso3.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp_UdUYkphpV"
      },
      "outputs": [],
      "source": [
        "# FAIXAS\n",
        "\n",
        "# Função Trimestral\n",
        "\n",
        "def func_trimestre_01(x):\n",
        "  if x == 1:\n",
        "    return \"primeiro\"\n",
        "  elif x == 2:\n",
        "    return \"primeiro\"\n",
        "  elif x == 3:\n",
        "    return \"primeiro\"\n",
        "  elif x == 4:\n",
        "    return \"segundo\"\n",
        "  elif x == 5:\n",
        "    return \"segundo\"\n",
        "  elif x == 6:\n",
        "    return \"segundo\"\n",
        "  elif x == 7:\n",
        "    return \"terceiro\"\n",
        "  elif x == 8:\n",
        "    return \"terceiro\"\n",
        "  elif x == 9:\n",
        "    return \"terceiro\"\n",
        "  else:\n",
        "    return \"quarto\"\n",
        "\n",
        "# Função para semestre hidrológico\n",
        "\n",
        "def func_sh_01(x):\n",
        "  if x == 1:\n",
        "    return \"chuva\"\n",
        "  elif x == 2:\n",
        "    return \"chuva\"\n",
        "  elif x == 3:\n",
        "    return \"chuva\"\n",
        "  elif x == 4:\n",
        "    return \"seca\"\n",
        "  elif x == 5:\n",
        "    return \"seca\"\n",
        "  elif x == 6:\n",
        "    return \"seca\"\n",
        "  elif x == 7:\n",
        "    return \"seca\"\n",
        "  elif x == 8:\n",
        "    return \"seca\"\n",
        "  elif x == 9:\n",
        "    return \"seca\"\n",
        "  else:\n",
        "    return \"chuva\"\n",
        "\n",
        "# Função para Áreas Municipais\n",
        "\n",
        "def func_area_01(x):\n",
        "  if x <= 2700:\n",
        "    return 1\n",
        "  elif x <= 5350:\n",
        "    return 2\n",
        "  elif x <= 8630:\n",
        "    return 3\n",
        "  else:\n",
        "    return 4\n",
        "\n",
        "# Funções para Faixas de Custeio\n",
        "\n",
        "# Mensal\n",
        "\n",
        "def func_faixa_m_01(x):\n",
        "  if x <= 150000:\n",
        "    return 1\n",
        "  elif x <= 2000000:\n",
        "    return 10\n",
        "  else:\n",
        "    return 20\n",
        "\n",
        "# Trimestral\n",
        "\n",
        "def func_faixa_t_01(x):\n",
        "  if x <= 500000:\n",
        "    return 1\n",
        "  elif x <= 5000000:\n",
        "    return 10\n",
        "  else:\n",
        "    return 20\n",
        "\n",
        "# Semestral\n",
        "\n",
        "def func_faixa_s_01(x):\n",
        "  if x <= 1000000:\n",
        "    return 1\n",
        "  elif x <= 10000000:\n",
        "    return 10\n",
        "  else:\n",
        "    return 20\n",
        "\n",
        "# Anual\n",
        "\n",
        "def func_faixa_a_01(x):\n",
        "  if x <= 2000000:\n",
        "    return 1\n",
        "  elif x <= 20000000:\n",
        "    return 10\n",
        "  else:\n",
        "    return 20\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKC293nIphvo"
      },
      "outputs": [],
      "source": [
        "# Faixas\n",
        "custeio_meso3['AR_MUN_2022'] = custeio_meso3['AR_MUN_2022'].apply(func_area_01)\n",
        "custeio_meso3['TRIMESTRE'] = custeio_meso3['MesEmissao'].apply(func_trimestre_01)\n",
        "custeio_meso3['SEMESTRE'] = custeio_meso3['MesEmissao'].apply(func_sh_01)\n",
        "\n",
        "custeio_meso3.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SAAb4pBqX_W"
      },
      "outputs": [],
      "source": [
        "nomeProduto = ['\"MILHO\"', '\"BOVINOS\"', '\"CAFÉ\"', '\"SOJA\"', '\"SUÍNOS\"', '\"AVICULTURA\"',\n",
        "           '\"ALHO\"',  '\"MORANGO\"','\"OVINOS\"','\"PLANTAS ORNAMENTAIS\"',\n",
        "           '\"EUCALIPTO\"', '\"CANA-DE-AÇUCAR\"','\"TANGERINA\"','\"TOMATE\"','\"TRIGO\"','\"UVA\"']\n",
        "\n",
        "# Filtrar os dados para o estado desejado (cdEstado = 12) e selecionar apenas as colunas relevantes\n",
        "dados_filtrados = custeio_meso3[(custeio_meso3[\"cdEstado\"] == 12)][[\"Nome_Mesorregião\", \"nomeProduto\", \"AnoEmissao\", \"VlCusteio\"]]\n",
        "\n",
        "# Loop pelos nomeProduto para gerar os gráficos\n",
        "for produto in nomeProduto:\n",
        "    # Filtrar os dados pelo nomeProduto atual\n",
        "    dados_produto = dados_filtrados[dados_filtrados[\"nomeProduto\"] == produto]\n",
        "\n",
        "    # Calcular o valor mediano de VlCusteio agrupado por ano e Nome_Mesorregião\n",
        "    median_values = dados_produto.groupby([\"AnoEmissao\", \"Nome_Mesorregião\"])[\"VlCusteio\"].median().reset_index()\n",
        "\n",
        "    # Plotar o gráfico de barras horizontais\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=median_values, x=\"VlCusteio\", y=\"Nome_Mesorregião\", hue=\"AnoEmissao\", orient=\"h\")\n",
        "    plt.xlabel(\"Valor Mediano de VlCusteio\")\n",
        "    plt.ylabel(\"Nome_Mesorregião\")\n",
        "    plt.title(f\"Gráfico de Barras Horizontais - {produto}\")\n",
        "    plt.legend(title=\"AnoEmissao\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV9YvvnoqYDE"
      },
      "outputs": [],
      "source": [
        "nomeProduto = ['\"MILHO\"', '\"BOVINOS\"', '\"CAFÉ\"', '\"SOJA\"', '\"SUÍNOS\"', '\"AVICULTURA\"',\n",
        "           '\"ALHO\"',  '\"MORANGO\"','\"OVINOS\"','\"PLANTAS ORNAMENTAIS\"',\n",
        "           '\"EUCALIPTO\"', '\"CANA-DE-AÇUCAR\"','\"TANGERINA\"','\"TOMATE\"','\"TRIGO\"','\"UVA\"']\n",
        "\n",
        "# Filtrar os dados para o estado desejado (cdEstado = 12) e selecionar apenas as colunas relevantes\n",
        "dados_filtrados = custeio_meso3[(custeio_meso3[\"cdEstado\"] == 12)][[\"Nome_Mesorregião\", \"nomeProduto\", \"SEMESTRE\", \"VlCusteio\"]]\n",
        "\n",
        "# Loop pelos nomeProduto para gerar os gráficos\n",
        "for produto in nomeProduto:\n",
        "    # Filtrar os dados pelo nomeProduto atual\n",
        "    dados_produto = dados_filtrados[dados_filtrados[\"nomeProduto\"] == produto]\n",
        "\n",
        "    # Calcular o valor mediano de VlCusteio agrupado por SEMESTRE e Nome_Mesorregião\n",
        "    median_values = dados_produto.groupby([\"SEMESTRE\", \"Nome_Mesorregião\"])[\"VlCusteio\"].median().reset_index()\n",
        "\n",
        "    # Plotar o gráfico de barras horizontais\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=median_values, x=\"VlCusteio\", y=\"Nome_Mesorregião\", hue=\"SEMESTRE\", orient=\"h\")\n",
        "    plt.xlabel(\"Valor Mediano de VlCusteio\")\n",
        "    plt.ylabel(\"Nome_Mesorregião\")\n",
        "    plt.title(f\"Gráfico de Barras Horizontais - {produto}\")\n",
        "    plt.legend(title=\"SEMESTRE\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4YZ_X8kqYG4"
      },
      "outputs": [],
      "source": [
        "nomeProduto = ['\"MILHO\"', '\"BOVINOS\"', '\"CAFÉ\"', '\"SOJA\"', '\"SUÍNOS\"', '\"AVICULTURA\"',\n",
        "           '\"ALHO\"',  '\"MORANGO\"','\"OVINOS\"','\"PLANTAS ORNAMENTAIS\"',\n",
        "           '\"EUCALIPTO\"', '\"CANA-DE-AÇUCAR\"','\"TANGERINA\"','\"TOMATE\"','\"TRIGO\"','\"UVA\"']\n",
        "\n",
        "# Filtrar os dados para o estado desejado (cdEstado = 12) e selecionar apenas as colunas relevantes\n",
        "dados_filtrados = custeio_meso3[(custeio_meso3[\"cdEstado\"] == 12)][[\"Nome_Mesorregião\", \"nomeProduto\", \"TRIMESTRE\", \"VlCusteio\"]]\n",
        "\n",
        "# Loop pelos nomeProduto para gerar os gráficos\n",
        "for produto in nomeProduto:\n",
        "    # Filtrar os dados pelo nomeProduto atual\n",
        "    dados_produto = dados_filtrados[dados_filtrados[\"nomeProduto\"] == produto]\n",
        "\n",
        "    # Calcular o valor mediano de VlCusteio agrupado por TRIMESTRE e Nome_Mesorregião\n",
        "    median_values = dados_produto.groupby([\"TRIMESTRE\", \"Nome_Mesorregião\"])[\"VlCusteio\"].median().reset_index()\n",
        "\n",
        "    # Plotar o gráfico de barras horizontais\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=median_values, x=\"VlCusteio\", y=\"Nome_Mesorregião\", hue=\"TRIMESTRE\", orient=\"h\")\n",
        "    plt.xlabel(\"Valor Mediano de VlCusteio\")\n",
        "    plt.ylabel(\"Nome_Mesorregião\")\n",
        "    plt.title(f\"Gráfico de Barras Horizontais - {produto}\")\n",
        "    plt.legend(title=\"TRIMESTRE\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3SVoN053Ut6"
      },
      "outputs": [],
      "source": [
        "nomeProduto = ['\"MILHO\"', '\"BOVINOS\"', '\"CAFÉ\"', '\"SOJA\"', '\"SUÍNOS\"', '\"AVICULTURA\"',\n",
        "           '\"ALHO\"',  '\"MORANGO\"','\"OVINOS\"','\"PLANTAS ORNAMENTAIS\"',\n",
        "           '\"EUCALIPTO\"', '\"CANA-DE-AÇUCAR\"','\"TANGERINA\"','\"TOMATE\"','\"TRIGO\"','\"UVA\"']\n",
        "\n",
        "# Filtrar os dados para o estado desejado (cdEstado = 12) e selecionar apenas as colunas relevantes\n",
        "dados_filtrados = custeio_meso3[(custeio_meso3[\"cdEstado\"] == 12)][[\"Nome_Mesorregião\", \"nomeProduto\", \"MesEmissao\", \"VlCusteio\"]]\n",
        "\n",
        "# Loop pelos nomeProduto para gerar os gráficos\n",
        "for produto in nomeProduto:\n",
        "    # Filtrar os dados pelo nomeProduto atual\n",
        "    dados_produto = dados_filtrados[dados_filtrados[\"nomeProduto\"] == produto]\n",
        "\n",
        "    # Calcular o valor mediano de VlCusteio agrupado por MesEmissao e Nome_Mesorregião\n",
        "    median_values = dados_produto.groupby([\"MesEmissao\", \"Nome_Mesorregião\"])[\"VlCusteio\"].median().reset_index()\n",
        "\n",
        "    # Plotar o gráfico de barras horizontais\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=median_values, x=\"VlCusteio\", y=\"Nome_Mesorregião\", hue=\"MesEmissao\", orient=\"h\")\n",
        "    plt.xlabel(\"Valor Mediano de VlCusteio\")\n",
        "    plt.ylabel(\"Nome_Mesorregião\")\n",
        "    plt.title(f\"Gráfico de Barras Horizontais - {produto}\")\n",
        "    plt.legend(title=\"MesEmissao\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr6SFuIA3U0t"
      },
      "outputs": [],
      "source": [
        "nomeProduto = ['\"MILHO\"', '\"BOVINOS\"', '\"CAFÉ\"', '\"SOJA\"', '\"SUÍNOS\"', '\"AVICULTURA\"',\n",
        "           '\"ALHO\"',  '\"MORANGO\"','\"OVINOS\"','\"PLANTAS ORNAMENTAIS\"',\n",
        "           '\"EUCALIPTO\"', '\"CANA-DE-AÇUCAR\"','\"TANGERINA\"','\"TOMATE\"','\"TRIGO\"','\"UVA\"']\n",
        "\n",
        "# Filtrar os dados para cada nomeProduto e selecionar apenas as colunas relevantes\n",
        "for produto in nomeProduto:\n",
        "    dados_produto = custeio_meso3[custeio_meso3[\"nomeProduto\"] == produto][[\"AR_MUN_2022\", \"AnoEmissao\", \"VlCusteio\"]]\n",
        "\n",
        "    # Calcular o valor mediano de VlCusteio agrupado por AR_MUN_2022 e AnoEmissao\n",
        "    median_values = dados_produto.groupby([\"AR_MUN_2022\", \"AnoEmissao\"])[\"VlCusteio\"].median().reset_index()\n",
        "\n",
        "    # Plotar o gráfico de barras horizontais\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(data=median_values, x=\"VlCusteio\", y=\"AR_MUN_2022\", hue=\"AnoEmissao\", orient=\"h\")\n",
        "    plt.xlabel(\"Valor Mediano de VlCusteio\")\n",
        "    plt.ylabel(\"AR_MUN_2022\")\n",
        "    plt.title(f\"Gráfico de Barras Horizontais - {produto}\")\n",
        "    plt.legend(title=\"AnoEmissao\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfnGlPgjUB5x"
      },
      "outputs": [],
      "source": [
        "# Lista de nomeProduto\n",
        "selecao = ['\"BOVINOS\"','\"CAFÉ\"', '\"MILHO\"', '\"SOJA\"']\n",
        "\n",
        "# Filtrar o dataframe original pela seleção de nomeProduto\n",
        "df_selecao = custeio_meso[custeio_meso['nomeProduto'].isin(selecao)]\n",
        "\n",
        "# Calcular a média anual de VlCusteio por nomeProduto e Nome_Mesorregião\n",
        "df_mediana_anual = df_selecao.groupby(['nomeProduto', 'Municipio','AnoEmissao','Nome_Mesorregião'])['VlCusteio'].median().reset_index()\n",
        "df_media_anual = df_mediana_anual.groupby(['nomeProduto','Nome_Mesorregião'])['VlCusteio'].mean().reset_index()\n",
        "\n",
        "# Criar tabela pivot usando pivot_table()\n",
        "df_pivot = pd.pivot_table(df_media_anual, index='nomeProduto', columns='Nome_Mesorregião', values='VlCusteio')\n",
        "\n",
        "# Transpor a tabela (inverter linhas e colunas)\n",
        "df_pivot = df_pivot.transpose()\n",
        "\n",
        "# Formatar a tabela com duas casas decimais e separador de milhar\n",
        "df_pivot = df_pivot.round(2).applymap('{:,.0f}'.format)\n",
        "\n",
        "# Exibir a tabela resultante\n",
        "print(df_pivot)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0HWLWQRUB5z"
      },
      "outputs": [],
      "source": [
        "# Lista de nomeProduto\n",
        "selecao = ['\"BOVINOS\"','\"CAFÉ\"', '\"MILHO\"', '\"SOJA\"']\n",
        "\n",
        "# Filtrar o dataframe original pela seleção de nomeProduto\n",
        "df_selecao = custeio_meso[custeio_meso['nomeProduto'].isin(selecao)]\n",
        "\n",
        "# Calcular a média anual de VlCusteio por nomeProduto e Nome_Mesorregião\n",
        "df_mediana_anual = df_selecao.groupby(['nomeProduto', 'Municipio','AnoEmissao','Nome_Mesorregião'])['VlCusteio'].sum().reset_index()\n",
        "df_media_anual = df_mediana_anual.groupby(['nomeProduto','Nome_Mesorregião'])['VlCusteio'].mean().reset_index()\n",
        "\n",
        "# Criar tabela pivot usando pivot_table()\n",
        "df_pivot = pd.pivot_table(df_media_anual, index='nomeProduto', columns='Nome_Mesorregião', values='VlCusteio')\n",
        "\n",
        "# Transpor a tabela (inverter linhas e colunas)\n",
        "df_pivot = df_pivot.transpose()\n",
        "\n",
        "# Formatar a tabela com duas casas decimais e separador de milhar\n",
        "df_pivot = df_pivot.round(2).applymap('{:,.0f}'.format)\n",
        "\n",
        "# Exibir a tabela resultante\n",
        "print(df_pivot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Qvfl7s3U7X"
      },
      "outputs": [],
      "source": [
        "# Agrupar por nomeProduto, Nome_Mesorregião e Microrregião e calcular a média de VlCusteio por Município por Ano\n",
        "df_grouped2 = custeio_meso.groupby(['nomeProduto','AnoEmissao', 'Municipio','Nome_Mesorregião',\n",
        "                                    'Nome_Microrregião'])['VlCusteio'].sum().reset_index()\n",
        "df_grouped2 = df_grouped2.groupby(['nomeProduto','Nome_Mesorregião','Nome_Microrregião'])['VlCusteio'].mean().reset_index()\n",
        "df_grouped2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9Q_6ufSAEJz"
      },
      "outputs": [],
      "source": [
        "meso = ['Zona da Mata']\n",
        "df_grouped3 = df_grouped2[df_grouped2['Nome_Mesorregião'].isin(meso)]\n",
        "\n",
        "# Agrupar os dados por microrregião e somar os valores de VlCusteio para cada produto\n",
        "df_sum_vlcusteio = df_grouped3.groupby(['Nome_Microrregião', 'nomeProduto'])['VlCusteio'].sum()\n",
        "\n",
        "# Obter os cinco principais produtos por microrregião\n",
        "df_top_products = df_sum_vlcusteio.groupby('Nome_Microrregião').nlargest(5).reset_index(level=1, drop=True).reset_index()\n",
        "\n",
        "# Iterar sobre os grupos e gerar os gráficos\n",
        "for microrregiao, df_top in df_top_products.groupby('Nome_Microrregião'):\n",
        "    plt.figure()\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(df_top['nomeProduto'], df_top['VlCusteio'])\n",
        "    plt.xlabel('VlCusteio')\n",
        "    plt.ylabel('Nome do Produto')\n",
        "    plt.title(f'5 Principais Produtos - Microrregião: {microrregiao}')\n",
        "    plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxokjxSnqYKX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz1s6KkQYo9D"
      },
      "source": [
        "## Modelo para previsão em 3 (três) faixas de valores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYsMzgZScYV0"
      },
      "source": [
        "### Criação das funções de definição de faixas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzTZ3kHscYlS"
      },
      "outputs": [],
      "source": [
        "# Função Trimestral\n",
        "\n",
        "def func_trimestre(x):\n",
        "  if x == 1:\n",
        "    return \"primeiro\"\n",
        "  elif x == 2:\n",
        "    return \"primeiro\"\n",
        "  elif x == 3:\n",
        "    return \"primeiro\"\n",
        "  elif x == 4:\n",
        "    return \"segundo\"\n",
        "  elif x == 5:\n",
        "    return \"segundo\"\n",
        "  elif x == 6:\n",
        "    return \"segundo\"\n",
        "  elif x == 7:\n",
        "    return \"terceiro\"\n",
        "  elif x == 8:\n",
        "    return \"terceiro\"\n",
        "  elif x == 9:\n",
        "    return \"terceiro\"\n",
        "  else:\n",
        "    return \"quarto\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cquaxshWdLGm"
      },
      "outputs": [],
      "source": [
        "# Funções para Faixas de Custeio\n",
        "\n",
        "# Trimestral\n",
        "\n",
        "def func_faixa_t(x):\n",
        "  if x <= 125000:\n",
        "    return 1\n",
        "  elif x <= 750000:\n",
        "    return 10\n",
        "  else:\n",
        "    return 15\n",
        "\n",
        "\n",
        "# Anual\n",
        "\n",
        "def func_faixa_a(x):\n",
        "  if x <= 600000:\n",
        "    return 1\n",
        "  elif x <= 3000000:\n",
        "    return 5\n",
        "  else:\n",
        "    return 15\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDRgHhoBhYme"
      },
      "source": [
        "### Modelo Trimestral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKAJ4FflqJMo"
      },
      "outputs": [],
      "source": [
        "# Preparação das bases\n",
        "\n",
        "custeio_tf = custeio.copy()\n",
        "ibge_tf = ibge.copy()\n",
        "area_tf = area.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVX85bCkqJMu"
      },
      "outputs": [],
      "source": [
        "# Função trimestral\n",
        "\n",
        "custeio_tf['Trimestre'] = custeio_tf['MesEmissao'].apply(func_trimestre)\n",
        "custeio_tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a888A1YKq_Ym"
      },
      "outputs": [],
      "source": [
        "# Soma de VlCusteio por município por trimestre\n",
        "\n",
        "custeio_tf_s = custeio_tf.groupby(['Municipio', 'nomeProduto', 'AnoEmissao','Trimestre', 'cdEstado', 'codIbge'], as_index=False)['VlCusteio'].sum()\n",
        "custeio_tf_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39x_D50oqJMv"
      },
      "outputs": [],
      "source": [
        "# Escolha do estado (MG = 12), seleção dos objetos e filtragem da base custeio\n",
        "\n",
        "custeio_tf_mg = custeio_tf_s[custeio_tf_s['cdEstado'] == 12]\n",
        "valores_desejados = ['\"BOVINOS\"','\"CAFÉ\"', '\"MILHO\"', '\"SOJA\"']\n",
        "custeio_tf_mg_prod = custeio_tf_mg[custeio_tf_mg['nomeProduto'].isin(valores_desejados)]\n",
        "anos = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "custeio_tf_mg_prod = custeio_tf_mg_prod[custeio_tf_mg_prod['AnoEmissao'].isin(anos)]\n",
        "\n",
        "custeio_tf_mg_prod.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XLR2VnoqJMw"
      },
      "outputs": [],
      "source": [
        "# Merge das bases de dados\n",
        "\n",
        "custeio_tf_mg_prod_ibge = pd.merge(custeio_tf_mg_prod, ibge_tf, how = 'left')\n",
        "custeio_tf_mg_prod_ibge_area = pd.merge(custeio_tf_mg_prod_ibge, area_tf, how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPl1ahp5qJMw"
      },
      "outputs": [],
      "source": [
        "# Seleção das colunas\n",
        "\n",
        "custeio_tf_mg_prod_ibge_area_2 = custeio_tf_mg_prod_ibge_area[['nomeProduto',\t'Nome_Mesorregião', 'AnoEmissao', 'Trimestre', 'AR_MUN_2022','VlCusteio']]\n",
        "custeio_tf_mg_prod_ibge_area_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgaVQh5HqJMy"
      },
      "outputs": [],
      "source": [
        "# Utilização das faixas de valores de custeio\n",
        "\n",
        "custeio_tf_mg_prod_ibge_area_2['VlCusteio'] = custeio_tf_mg_prod_ibge_area_2['VlCusteio'].apply(func_faixa_t)\n",
        "custeio_tf_mg_prod_ibge_area_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo_0JpqzqJMy"
      },
      "outputs": [],
      "source": [
        "# Gera a lista de variáveis categóricas\n",
        "cols_cat_tf = custeio_tf_mg_prod_ibge_area_2.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "\n",
        "cols_cat_tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibLFaiVUqJMz"
      },
      "outputs": [],
      "source": [
        "# Criação dos dummies\n",
        "data_tf = pd.get_dummies(custeio_tf_mg_prod_ibge_area_2, columns=cols_cat_tf, drop_first=True)\n",
        "\n",
        "data_tf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaZ-ZLOgqJM0"
      },
      "outputs": [],
      "source": [
        "# Definição das variáveis dependentes e independentes\n",
        "\n",
        "X, y = data_tf.drop(['VlCusteio'], axis=1), data_tf['VlCusteio']\n",
        "class_names = data_tf['VlCusteio']\n",
        "\n",
        "# Particiona a base de dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TchIqRiYqJM0"
      },
      "outputs": [],
      "source": [
        "# Árvore de Decisão\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "tree_custo = tree_custo.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia (base de treinamento):\", tree_custo.score(X_train, y_train))\n",
        "y_pred = tree_custo.predict(X_test)\n",
        "print(\"Acurácia de previsão:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYEJjv5-BjZB"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpuitny4qJM1"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb = nb.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", nb.score(X_train, y_train))\n",
        "tp_nb = nb.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_nb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_nb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_nb)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InoUpysJBiBq"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKRngpr_qJM2"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando Gradiente Descendente\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd = SGDClassifier()\n",
        "sgd = sgd.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", sgd.score(X_train, y_train))\n",
        "tp_sgd = sgd.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_sgd))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_sgd))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_sgd)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3PSG7klBgoT"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j908o0iTqJM3"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando KNN (K - Nearest Neighbors)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn = knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", knn.score(X_train, y_train))\n",
        "tp_knn = knn.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_knn))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_knn))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_knn)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77vKZHzXBcXz"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cS2osbgsqJM3"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando Randon Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfm = RandomForestClassifier()\n",
        "rfm = rfm.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", rfm.score(X_train, y_train))\n",
        "tp_rfm = rfm.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_rfm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_rfm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_rfm)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p47TcAuBFvJ"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkrT8jP0BFvM"
      },
      "outputs": [],
      "source": [
        "# Modelo SVC\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", svm.score(X_train, y_train))\n",
        "tp_svm = svm.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_svm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_svm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_svm)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD-VjRnkBFvN"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y68rJCWmBFvO"
      },
      "outputs": [],
      "source": [
        "# GradientBoostingClassifier\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", gb.score(X_train, y_train))\n",
        "tp_gb = gb.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_gb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_gb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_gb)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C90ULWDUBFvP"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ChlSmTDBFvQ"
      },
      "outputs": [],
      "source": [
        "# AdaBoostClassifier\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", ada.score(X_train, y_train))\n",
        "tp_ada = ada.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_ada))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_ada))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_ada)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-oWCtGaBFvR"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJGcOk0xBFvS"
      },
      "outputs": [],
      "source": [
        "# ExtraTreesClassifier\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier()\n",
        "et.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", et.score(X_train, y_train))\n",
        "tp_et = et.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_et))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_et))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_et)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6gzYr5sBFvT"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RsfvbZJBFvU"
      },
      "outputs": [],
      "source": [
        "# LogisticRegression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", lr.score(X_train, y_train))\n",
        "tp_lr = lr.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_lr))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_lr))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_lr)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adkzwSigBFvV"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XW66HKxuAbr6"
      },
      "outputs": [],
      "source": [
        "# Armazena os resultados em um dicionário\n",
        "resultados = {\n",
        "        'Árvore de Decisão': {\n",
        "            'Acurácia Treinamento': tree_custo.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, y_pred)\n",
        "        },\n",
        "        'Naive Bayes': {\n",
        "            'Acurácia Treinamento': nb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_nb)\n",
        "        },\n",
        "        'Gradiente Descendente': {\n",
        "            'Acurácia Treinamento': sgd.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_sgd)\n",
        "        },\n",
        "        'KNN': {\n",
        "            'Acurácia Treinamento': knn.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_knn)\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'Acurácia Treinamento': rfm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_rfm)\n",
        "        },\n",
        "        'SVC': {\n",
        "            'Acurácia Treinamento': svm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_svm)\n",
        "        },\n",
        "        'GradientBoostingClassifier': {\n",
        "            'Acurácia Treinamento': gb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_gb)\n",
        "        },\n",
        "        'AdaBoostClassifier': {\n",
        "            'Acurácia Treinamento': ada.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_ada)\n",
        "        },\n",
        "        'ExtraTreesClassifier': {\n",
        "            'Acurácia Treinamento': et.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_et)\n",
        "        },\n",
        "        'Regressão Logística': {\n",
        "            'Acurácia Treinamento': lr.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_lr)\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "# Criar e exibir as tabelas de resultados\n",
        "for modelo, resultado in resultados.items():\n",
        "    df_resultados = pd.DataFrame.from_dict(resultado, orient='index', columns=['Valor'])\n",
        "    df_resultados.index.name = modelo\n",
        "    print(df_resultados)\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QtKrXftTcpS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfwWKjx8LUyi"
      },
      "source": [
        "### Modelo Trimestral (Sem 'AnoEmissao')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvKlXceULUym"
      },
      "outputs": [],
      "source": [
        "# Preparação das bases\n",
        "\n",
        "custeio_tf = custeio.copy()\n",
        "ibge_tf = ibge.copy()\n",
        "area_tf = area.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyz2zx-oLUyo"
      },
      "outputs": [],
      "source": [
        "# Função trimestral\n",
        "\n",
        "custeio_tf['Trimestre'] = custeio_tf['MesEmissao'].apply(func_trimestre)\n",
        "custeio_tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GTJEqkQLUyp"
      },
      "outputs": [],
      "source": [
        "# Soma de VlCusteio por município por trimestre\n",
        "\n",
        "custeio_tf_s = custeio_tf.groupby(['Municipio', 'nomeProduto', 'AnoEmissao','Trimestre', 'cdEstado', 'codIbge'], as_index=False)['VlCusteio'].sum()\n",
        "custeio_tf_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJwvWpmgLUyq"
      },
      "outputs": [],
      "source": [
        "# Escolha do estado (MG = 12), seleção dos objetos e filtragem da base custeio\n",
        "\n",
        "custeio_tf_mg = custeio_tf_s[custeio_tf_s['cdEstado'] == 12]\n",
        "valores_desejados = ['\"BOVINOS\"','\"CAFÉ\"', '\"MILHO\"', '\"SOJA\"']\n",
        "custeio_tf_mg_prod = custeio_tf_mg[custeio_tf_mg['nomeProduto'].isin(valores_desejados)]\n",
        "anos = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "custeio_tf_mg_prod = custeio_tf_mg_prod[custeio_tf_mg_prod['AnoEmissao'].isin(anos)]\n",
        "\n",
        "custeio_tf_mg_prod.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eauB4PL0LUyr"
      },
      "outputs": [],
      "source": [
        "# Merge das bases de dados\n",
        "\n",
        "custeio_tf_mg_prod_ibge = pd.merge(custeio_tf_mg_prod, ibge_tf, how = 'left')\n",
        "custeio_tf_mg_prod_ibge_area = pd.merge(custeio_tf_mg_prod_ibge, area_tf, how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ivmqk3YLUys"
      },
      "outputs": [],
      "source": [
        "# Seleção das colunas\n",
        "\n",
        "custeio_tf_mg_prod_ibge_area_2 = custeio_tf_mg_prod_ibge_area[['nomeProduto',\t'Nome_Mesorregião', 'Trimestre', 'AR_MUN_2022','VlCusteio']]\n",
        "custeio_tf_mg_prod_ibge_area_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AP0mcXgrLUyt"
      },
      "outputs": [],
      "source": [
        "# Utilização das faixas de valores de custeio\n",
        "\n",
        "custeio_tf_mg_prod_ibge_area_2['VlCusteio'] = custeio_tf_mg_prod_ibge_area_2['VlCusteio'].apply(func_faixa_t)\n",
        "custeio_tf_mg_prod_ibge_area_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6l3DquuLUyu"
      },
      "outputs": [],
      "source": [
        "# Gera a lista de variáveis categóricas\n",
        "cols_cat_tf = custeio_tf_mg_prod_ibge_area_2.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "\n",
        "cols_cat_tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ewee_LZgLUyv"
      },
      "outputs": [],
      "source": [
        "# Criação dos dummies\n",
        "data_tf = pd.get_dummies(custeio_tf_mg_prod_ibge_area_2, columns=cols_cat_tf, drop_first=True)\n",
        "\n",
        "data_tf.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iyiyhh0LUyw"
      },
      "outputs": [],
      "source": [
        "# Definição das variáveis dependentes e independentes\n",
        "\n",
        "X, y = data_tf.drop(['VlCusteio'], axis=1), data_tf['VlCusteio']\n",
        "class_names = data_tf['VlCusteio']\n",
        "\n",
        "# Particiona a base de dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_ZGDDP5LUyw"
      },
      "outputs": [],
      "source": [
        "# Árvore de Decisão\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "tree_custo = tree_custo.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia (base de treinamento):\", tree_custo.score(X_train, y_train))\n",
        "y_pred = tree_custo.predict(X_test)\n",
        "print(\"Acurácia de previsão:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ip8BcfwnLUyx"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8Ou4c0zLUyy"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb = nb.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", nb.score(X_train, y_train))\n",
        "tp_nb = nb.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_nb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_nb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_nb)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaHTEgwqLUyy"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kyln7WAYLUyz"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando Gradiente Descendente\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd = SGDClassifier()\n",
        "sgd = sgd.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", sgd.score(X_train, y_train))\n",
        "tp_sgd = sgd.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_sgd))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_sgd))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_sgd)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm2LjAEILUy0"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBBGbY05LUy0"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando KNN (K - Nearest Neighbors)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn = knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", knn.score(X_train, y_train))\n",
        "tp_knn = knn.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_knn))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_knn))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_knn)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCB4JDWHLUy1"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PhNWhhALUy1"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando Randon Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfm = RandomForestClassifier()\n",
        "rfm = rfm.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", rfm.score(X_train, y_train))\n",
        "tp_rfm = rfm.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_rfm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_rfm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_rfm)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_tf['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2-BCNhULUy2"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JLriaysLUy2"
      },
      "outputs": [],
      "source": [
        "# Modelo SVC\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", svm.score(X_train, y_train))\n",
        "tp_svm = svm.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_svm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_svm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_svm)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cx9ChK1JLUy3"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9DYXTsxLUy3"
      },
      "outputs": [],
      "source": [
        "# GradientBoostingClassifier\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", gb.score(X_train, y_train))\n",
        "tp_gb = gb.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_gb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_gb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_gb)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kIY29cKLUy4"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mxp21bxRLUy4"
      },
      "outputs": [],
      "source": [
        "# AdaBoostClassifier\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", ada.score(X_train, y_train))\n",
        "tp_ada = ada.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_ada))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_ada))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_ada)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlehyTHELUy5"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-_x9cnALUy5"
      },
      "outputs": [],
      "source": [
        "# ExtraTreesClassifier\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier()\n",
        "et.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", et.score(X_train, y_train))\n",
        "tp_et = et.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_et))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_et))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_et)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdMvoGFeLUy6"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_8uOHmHLUy6"
      },
      "outputs": [],
      "source": [
        "# LogisticRegression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", lr.score(X_train, y_train))\n",
        "tp_lr = lr.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_lr))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_lr))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_lr)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_tf['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_tf['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwQhUk4BLUy6"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbecyCY-LUy7"
      },
      "outputs": [],
      "source": [
        "# Armazena os resultados em um dicionário\n",
        "resultados = {\n",
        "        'Árvore de Decisão': {\n",
        "            'Acurácia Treinamento': tree_custo.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, y_pred)\n",
        "        },\n",
        "        'Naive Bayes': {\n",
        "            'Acurácia Treinamento': nb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_nb)\n",
        "        },\n",
        "        'Gradiente Descendente': {\n",
        "            'Acurácia Treinamento': sgd.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_sgd)\n",
        "        },\n",
        "        'KNN': {\n",
        "            'Acurácia Treinamento': knn.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_knn)\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'Acurácia Treinamento': rfm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_rfm)\n",
        "        },\n",
        "        'SVC': {\n",
        "            'Acurácia Treinamento': svm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_svm)\n",
        "        },\n",
        "        'GradientBoostingClassifier': {\n",
        "            'Acurácia Treinamento': gb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_gb)\n",
        "        },\n",
        "        'AdaBoostClassifier': {\n",
        "            'Acurácia Treinamento': ada.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_ada)\n",
        "        },\n",
        "        'ExtraTreesClassifier': {\n",
        "            'Acurácia Treinamento': et.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_et)\n",
        "        },\n",
        "        'Regressão Logística': {\n",
        "            'Acurácia Treinamento': lr.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_lr)\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "# Criar e exibir as tabelas de resultados\n",
        "for modelo, resultado in resultados.items():\n",
        "    df_resultados = pd.DataFrame.from_dict(resultado, orient='index', columns=['Valor'])\n",
        "    df_resultados.index.name = modelo\n",
        "    print(df_resultados)\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNQFNLDjpNZ5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# Dados de acurácia para treino e teste\n",
        "modelos = ['Árvore de Decisão', 'Naive Bayes', 'Gradiente Descendente', 'KNN',\n",
        "           'Random Forest', 'SVC', 'GradientBoostingClassifier', 'AdaBoostClassifier',\n",
        "           'ExtraTreesClassifier', 'Regressão Logística']\n",
        "\n",
        "acuracia_treino = [0.768697, 0.407952, 0.490372, 0.746676, 0.768670, 0.488324,\n",
        "                   0.608032, 0.574920, 0.768697, 0.558298]\n",
        "\n",
        "acuracia_teste = [0.672331, 0.407053, 0.485400, 0.655178, 0.671374, 0.481809,\n",
        "                  0.594862, 0.564465, 0.671374, 0.549067]\n",
        "\n",
        "# Configuração do gráfico\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "indice = np.arange(len(modelos))\n",
        "largura = 0.35\n",
        "\n",
        "# Barras de acurácia para treino e teste\n",
        "rects1 = ax.barh(indice - largura/2, acuracia_treino, largura, label='Treinamento')\n",
        "rects2 = ax.barh(indice + largura/2, acuracia_teste, largura, label='Teste')\n",
        "\n",
        "# Rótulos, título e legenda\n",
        "ax.set_yticks(indice)\n",
        "ax.set_yticklabels(modelos)\n",
        "ax.set_xlabel('Acurácia')\n",
        "ax.set_title('Acurácia de Treinamento e Teste por Modelo')\n",
        "ax.legend()\n",
        "\n",
        "# Adiciona rótulos nas barras\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        width = rect.get_width()\n",
        "        ax.annotate(f'{width:.2f}', xy=(width, rect.get_y() + rect.get_height() / 2),\n",
        "                    xytext=(3, 0), textcoords=\"offset points\",\n",
        "                    ha='left', va='center')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97rH8nm31ChG"
      },
      "source": [
        "### Modelo Anual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gYxkFTYh1ChI"
      },
      "outputs": [],
      "source": [
        "# Preparação das bases\n",
        "\n",
        "custeio_af = custeio.copy()\n",
        "ibge_af = ibge.copy()\n",
        "area_af = area.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTizXkqk1ChK"
      },
      "outputs": [],
      "source": [
        "# Soma de VlCusteio por município por ano\n",
        "\n",
        "custeio_af_s = custeio_af.groupby(['Municipio', 'nomeProduto', 'AnoEmissao', 'cdEstado', 'codIbge'], as_index=False)['VlCusteio'].sum()\n",
        "custeio_af_s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtcLUbYs1ChL"
      },
      "outputs": [],
      "source": [
        "# Escolha do estado (MG = 12), seleção dos objetos e filtragem da base custeio\n",
        "\n",
        "custeio_af_mg = custeio_af_s[custeio_af_s['cdEstado'] == 12]\n",
        "valores_desejados = ['\"BOVINOS\"','\"CAFÉ\"', '\"MILHO\"', '\"SOJA\"']\n",
        "custeio_af_mg_prod = custeio_af_mg[custeio_af_mg['nomeProduto'].isin(valores_desejados)]\n",
        "\n",
        "anos = [2019, 2020, 2021, 2022]#[2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "custeio_af_mg_prod = custeio_af_mg_prod[custeio_af_mg_prod['AnoEmissao'].isin(anos)]\n",
        "\n",
        "custeio_af_mg_prod.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVSkLK9Y1ChM"
      },
      "outputs": [],
      "source": [
        "# Merge das bases de dados\n",
        "\n",
        "custeio_af_mg_prod_ibge = pd.merge(custeio_af_mg_prod, ibge_af, how = 'left')\n",
        "custeio_af_mg_prod_ibge_area = pd.merge(custeio_af_mg_prod_ibge, area_af, how = 'left')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMWSz_WS1ChN"
      },
      "outputs": [],
      "source": [
        "# Seleção das colunas\n",
        "\n",
        "custeio_af_mg_prod_ibge_area_2 = custeio_af_mg_prod_ibge_area[['nomeProduto',\t'Nome_Mesorregião','AR_MUN_2022','VlCusteio']]\n",
        "custeio_af_mg_prod_ibge_area_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-x_9TCU1ChO"
      },
      "outputs": [],
      "source": [
        "# Utilização das faixas de valores de custeio\n",
        "\n",
        "custeio_af_mg_prod_ibge_area_2['VlCusteio'] = custeio_af_mg_prod_ibge_area_2['VlCusteio'].apply(func_faixa_a)\n",
        "custeio_af_mg_prod_ibge_area_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ka7CFJUn1ChP"
      },
      "outputs": [],
      "source": [
        "# Gera a lista de variáveis categóricas\n",
        "cols_cat_af = custeio_af_mg_prod_ibge_area_2.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "cols_cat_af"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC2U5qvl1ChQ"
      },
      "outputs": [],
      "source": [
        "# Cria Dummies\n",
        "data_af = pd.get_dummies(custeio_af_mg_prod_ibge_area_2, columns=cols_cat_af, drop_first=True)\n",
        "\n",
        "data_af.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVBovVsg1ChR"
      },
      "outputs": [],
      "source": [
        "# Definição das variáveis dependentes e independentes\n",
        "\n",
        "X, y = data_af.drop(['VlCusteio'], axis=1), data_af['VlCusteio']\n",
        "class_names = data_af['VlCusteio']\n",
        "\n",
        "# Particiona a base de dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FHVmIeM1ChS"
      },
      "outputs": [],
      "source": [
        "# Árvore de Decisão\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "tree_custo = tree_custo.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia (base de treinamento):\", tree_custo.score(X_train, y_train))\n",
        "y_pred = tree_custo.predict(X_test)\n",
        "print(\"Acurácia de previsão:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_af['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbitV4bMMzlO"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONR2R6mlVpjH"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "import graphviz\n",
        "\n",
        "# Treinamento do modelo\n",
        "tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "tree_custo = tree_custo.fit(X_train, y_train)\n",
        "\n",
        "# Converter os valores das classes para strings\n",
        "class_names = tree_custo.classes_.astype(str).tolist()\n",
        "\n",
        "# Gerar a figura da árvore de decisão\n",
        "dot_data = export_graphviz(tree_custo, out_file=None, feature_names=X_train.columns.tolist(), class_names=class_names, filled=True, rounded=True, special_characters=True)\n",
        "graph = graphviz.Source(dot_data)\n",
        "\n",
        "# Exibir a figura da árvore de decisão\n",
        "graph.render(\"decision_tree\")  # Salvar a figura como arquivo \"decision_tree.pdf\"\n",
        "graph.view()  # Abrir visualização interativa da árvore de decisão\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0u7cnEG1ChT"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb = nb.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", nb.score(X_train, y_train))\n",
        "tp_nb = nb.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_nb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_nb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_nb)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_af['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70scL8XEMxQD"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkzP_rnI1ChT"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando Gradiente Descendente\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd = SGDClassifier()\n",
        "sgd = sgd.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", sgd.score(X_train, y_train))\n",
        "tp_sgd = sgd.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_sgd))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_sgd))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_sgd)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_af['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-FTRjDn3Muq5"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1gOOiRVD1ChU"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando KNN (K - Nearest Neighbors)\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn = knn.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", knn.score(X_train, y_train))\n",
        "tp_knn = knn.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_knn))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_knn))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_knn)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_af['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX0EB1_sMrQB"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnB_SaXO1ChV"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando Randon Forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfm = RandomForestClassifier()\n",
        "rfm = rfm.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", rfm.score(X_train, y_train))\n",
        "tp_rfm = rfm.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_rfm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_rfm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_rfm)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_af['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvvaikXbMoSK"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "appya6qNF8yr"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", svm.score(X_train, y_train))\n",
        "tp_svm = svm.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_svm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_svm))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_svm)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_af['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OqOoOqgfMlLI"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjkC7XjwF9Co"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", gb.score(X_train, y_train))\n",
        "tp_gb = gb.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_gb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_gb))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_gb)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_af['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpo5RdVzMi3s"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR9VuduGF9Ri"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", ada.score(X_train, y_train))\n",
        "tp_ada = ada.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_ada))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_ada))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_ada)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_af['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wm54ZM9bMgNW"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZxYSJGTF9ep"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "et = ExtraTreesClassifier()\n",
        "et.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", et.score(X_train, y_train))\n",
        "tp_et = et.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_et))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_et))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_et)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_af['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7zZczofMdoj"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miMKgKhQF-Mi"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"\")\n",
        "print(\"Acurácia: \", lr.score(X_train, y_train))\n",
        "tp_lr = lr.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_lr))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_lr))\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_lr)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_af['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_af['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CsCPIHhbHIAg"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xcj2lTSI7Fgx"
      },
      "outputs": [],
      "source": [
        "# Armazena os resultados em um dicionário\n",
        "resultados = {\n",
        "        'Árvore de Decisão': {\n",
        "            'Acurácia Treinamento': tree_custo.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, y_pred)\n",
        "        },\n",
        "        'Naive Bayes': {\n",
        "            'Acurácia Treinamento': nb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_nb)\n",
        "        },\n",
        "        'Gradiente Descendente': {\n",
        "            'Acurácia Treinamento': sgd.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_sgd)\n",
        "        },\n",
        "        'KNN': {\n",
        "            'Acurácia Treinamento': knn.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_knn)\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'Acurácia Treinamento': rfm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_rfm)\n",
        "        },\n",
        "        'SVC': {\n",
        "            'Acurácia Treinamento': svm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_svm)\n",
        "        },\n",
        "        'GradientBoostingClassifier': {\n",
        "            'Acurácia Treinamento': gb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_gb)\n",
        "        },\n",
        "        'AdaBoostClassifier': {\n",
        "            'Acurácia Treinamento': ada.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_ada)\n",
        "        },\n",
        "        'ExtraTreesClassifier': {\n",
        "            'Acurácia Treinamento': et.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_et)\n",
        "        },\n",
        "        'Regressão Logística': {\n",
        "            'Acurácia Treinamento': lr.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_lr)\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "# Criar e exibir as tabelas de resultados\n",
        "for modelo, resultado in resultados.items():\n",
        "    df_resultados = pd.DataFrame.from_dict(resultado, orient='index', columns=['Valor'])\n",
        "    df_resultados.index.name = modelo\n",
        "    print(df_resultados)\n",
        "    print('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3b0T4vLqzcH"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# Dados de acurácia para treino e teste\n",
        "modelos = ['Árvore de Decisão', 'Naive Bayes', 'Gradiente Descendente', 'KNN',\n",
        "           'Random Forest', 'SVC', 'GradientBoostingClassifier', 'AdaBoostClassifier',\n",
        "           'ExtraTreesClassifier', 'Regressão Logística']\n",
        "\n",
        "acuracia_treino = [0.861322, 0.444149, 0.485182, 0.766147, 0.861322, 0.486322,\n",
        "                   0.653875, 0.598594, 0.861322, 0.584536]\n",
        "\n",
        "acuracia_teste = [0.729345, 0.435328, 0.482051, 0.605698, 0.736752, 0.488319,\n",
        "                  0.645014, 0.609687, 0.733903, 0.583476]\n",
        "\n",
        "# Configuração do gráfico\n",
        "fig, ax = plt.subplots(figsize=(10, 6))  # Ajusta o tamanho da figura\n",
        "indice = np.arange(len(modelos))\n",
        "largura = 0.5  # Ajusta a largura das barras\n",
        "\n",
        "# Barras de acurácia para treino e teste\n",
        "rects1 = ax.barh(indice - largura/2, acuracia_treino, largura, label='Treinamento', color='blue')\n",
        "rects2 = ax.barh(indice + largura/2, acuracia_teste, largura, label='Teste', color='orange')\n",
        "\n",
        "# Rótulos, título e legenda\n",
        "ax.set_yticks(indice)\n",
        "ax.set_yticklabels(modelos)\n",
        "ax.set_xlabel('Acurácia')\n",
        "ax.set_title('Acurácia de Treinamento e Teste por Modelo')\n",
        "ax.legend()\n",
        "\n",
        "# Adiciona rótulos nas barras\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        width = rect.get_width()\n",
        "        ax.annotate(f'{width:.2f}', xy=(width, rect.get_y() + rect.get_height() / 2),\n",
        "                    xytext=(3, 0), textcoords=\"offset points\",\n",
        "                    ha='left', va='center')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCC0Hjx1KXuC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdAmYHdAQxoC"
      },
      "source": [
        "## Modelos Mesorregionais Anual e Trimestral Compactos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5BRl0Swsf6N"
      },
      "source": [
        "### Trimestral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IeEbGDE5WYKr"
      },
      "outputs": [],
      "source": [
        "# Função Trimestral\n",
        "def func_trimestre(x):\n",
        "  if x == 1:\n",
        "    return \"primeiro\"\n",
        "  elif x == 2:\n",
        "    return \"primeiro\"\n",
        "  elif x == 3:\n",
        "    return \"primeiro\"\n",
        "  elif x == 4:\n",
        "    return \"segundo\"\n",
        "  elif x == 5:\n",
        "    return \"segundo\"\n",
        "  elif x == 6:\n",
        "    return \"segundo\"\n",
        "  elif x == 7:\n",
        "    return \"terceiro\"\n",
        "  elif x == 8:\n",
        "    return \"terceiro\"\n",
        "  elif x == 9:\n",
        "    return \"terceiro\"\n",
        "  else:\n",
        "    return \"quarto\"\n",
        "\n",
        "\n",
        "# Função para Áreas Municipais\n",
        "def func_area(x):\n",
        "  if x <= 2700:\n",
        "    return 'Faixa 1'\n",
        "  elif x <= 5350:\n",
        "    return 'Faixa 2'\n",
        "  elif x <= 8630:\n",
        "    return 'Faixa 3'\n",
        "  else:\n",
        "    return 'Faixa 4'\n",
        "\n",
        "# Funções para Faixas de Custeio\n",
        "# Trimestral\n",
        "def func_faixa_t(x):\n",
        "  if x <= 125000:\n",
        "    return 1\n",
        "  elif x <= 750000:\n",
        "    return 10\n",
        "  else:\n",
        "    return 15\n",
        "\n",
        "\n",
        "# Preparação das bases\n",
        "custeio_mt = custeio.copy()\n",
        "ibge_mt = ibge.copy()\n",
        "area_mt = area.copy()\n",
        "\n",
        "# Aplicação da funcão trimestral\n",
        "custeio_mt['Trimestre'] = custeio_mt['MesEmissao'].apply(func_trimestre)\n",
        "\n",
        "# Soma de VlCusteio por município por trimestre\n",
        "custeio_mt_s = custeio_mt.groupby(['Municipio', 'nomeProduto', 'AnoEmissao','Trimestre', 'cdEstado', 'codIbge'], as_index=False)['VlCusteio'].sum()\n",
        "\n",
        "# Escolha do estado (MG = 12), seleção dos objetos e filtragem da base custeio\n",
        "custeio_mt_mg = custeio_mt_s[custeio_mt_s['cdEstado'] == 12]\n",
        "valores_desejados = ['\"BOVINOS\"','\"CAFÉ\"', '\"MILHO\"', '\"SOJA\"']\n",
        "custeio_mt_mg_prod = custeio_mt_mg[custeio_mt_mg['nomeProduto'].isin(valores_desejados)]\n",
        "anos = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "custeio_mt_mg_prod = custeio_mt_mg_prod[custeio_mt_mg_prod['AnoEmissao'].isin(anos)]\n",
        "\n",
        "# Merge das bases de dados\n",
        "custeio_mt_mg_prod_ibge = pd.merge(custeio_mt_mg_prod, ibge_mt, how = 'left')\n",
        "custeio_mt_mg_prod_ibge_area = pd.merge(custeio_mt_mg_prod_ibge, area_mt, how = 'left')\n",
        "\n",
        "# Seleção das colunas\n",
        "custeio_mt_mg_prod_ibge_area_2 = custeio_mt_mg_prod_ibge_area[['nomeProduto',\t'Nome_Mesorregião', 'Nome_Microrregião', 'Trimestre','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "# Utilização das faixas de valores de custeio\n",
        "custeio_mt_mg_prod_ibge_area_2['VlCusteio'] = custeio_mt_mg_prod_ibge_area_2['VlCusteio'].apply(func_faixa_t)\n",
        "\n",
        "# Identificação dos nomes das mesorregiões\n",
        "meso = custeio_mt_mg_prod_ibge_area_2['Nome_Mesorregião'].unique()\n",
        "\n",
        "# Criação de um dicionário para armazenar os resultados\n",
        "resultados = {}\n",
        "\n",
        "for nome in meso:\n",
        "  print('--------------------------------------------------------------------------------')\n",
        "  print(f'Análise da Mesorregiao: ',nome)\n",
        "\n",
        "  # Escolha da mesorregião\n",
        "  custeio_mt_mg_prod_ibge_area_3 = custeio_mt_mg_prod_ibge_area_2[custeio_mt_mg_prod_ibge_area_2['Nome_Mesorregião'] == nome]\n",
        "\n",
        "  # Identificação das Microrregiões de cada Mesorregião\n",
        "  micro = custeio_mt_mg_prod_ibge_area_3['Nome_Microrregião'].unique()\n",
        "  print(f'Essa Mesorregiao é formada por {len(micro)} Microrregiões: ',micro)\n",
        "\n",
        "  # Selecionar colunas\n",
        "  custeio_mt_mg_prod_ibge_area_3 = custeio_mt_mg_prod_ibge_area_3[['nomeProduto', 'Nome_Microrregião', 'Trimestre','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "  # Gera a lista de variáveis categóricas\n",
        "  cols_cat_mt = custeio_mt_mg_prod_ibge_area_3.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "  # Criação das colunas de Dummies\n",
        "  data_mt = pd.get_dummies(custeio_mt_mg_prod_ibge_area_3, columns=cols_cat_mt, drop_first=True)\n",
        "\n",
        "  # Definição das variáveis dependentes e independentes\n",
        "  X, y = data_mt.drop(['VlCusteio'], axis=1), data_mt['VlCusteio']\n",
        "  class_names = data_mt['VlCusteio']\n",
        "\n",
        "  # Particiona a base de dados\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
        "\n",
        "  # Árvore de Decisão\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "  tree_custo = tree_custo.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo de Árvore de Decisão - DecisionTreeClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento):\", tree_custo.score(X_train, y_train))\n",
        "  y_pred = tree_custo.predict(X_test)\n",
        "  print(\"Acurácia de previsão:\", accuracy_score(y_test, y_pred))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Naive Bayes\n",
        "  from sklearn.naive_bayes import GaussianNB\n",
        "  nb = GaussianNB()\n",
        "  b = nb.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo de Naive Bayes - GaussianNB\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", nb.score(X_train, y_train))\n",
        "  tp_nb = nb.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_nb))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_nb))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_nb)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando Gradiente Descendente\n",
        "  from sklearn.linear_model import SGDClassifier\n",
        "  sgd = SGDClassifier()\n",
        "  sgd = sgd.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Gradiente Descendente - SGDClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", sgd.score(X_train, y_train))\n",
        "  tp_sgd = sgd.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_sgd))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_sgd))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_sgd)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando KNN (K - Nearest Neighbors)\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn = knn.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo KNN (K - Nearest Neighbors) - KNeighborsClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", knn.score(X_train, y_train))\n",
        "  tp_knn = knn.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_knn))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_knn))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_knn)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando Randon Forest\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  rfm = RandomForestClassifier()\n",
        "  rfm = rfm.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Randon Forest - RandomForestClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", rfm.score(X_train, y_train))\n",
        "  tp_rfm = rfm.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_rfm))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_rfm))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_rfm)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo SVC\n",
        "  from sklearn.svm import SVC\n",
        "  svm = SVC()\n",
        "  svm.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo SVC - Support Vector Classification\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", svm.score(X_train, y_train))\n",
        "  tp_svm = svm.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_svm))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_svm))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_svm)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # GradientBoostingClassifier\n",
        "  from sklearn.ensemble import GradientBoostingClassifier\n",
        "  gb = GradientBoostingClassifier()\n",
        "  gb.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo GradientBoostingClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", gb.score(X_train, y_train))\n",
        "  tp_gb = gb.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_gb))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_gb))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_gb)\n",
        "  nf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo AdaBoostClassifier\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "  ada = AdaBoostClassifier()\n",
        "  ada.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo AdaBoostClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", ada.score(X_train, y_train))\n",
        "  tp_ada = ada.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_ada))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_ada))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_ada)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo ExtraTreesClassifier\n",
        "  from sklearn.ensemble import ExtraTreesClassifier\n",
        "  et = ExtraTreesClassifier()\n",
        "  et.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo ExtraTreesClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", et.score(X_train, y_train))\n",
        "  tp_et = et.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_et))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_et))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_et)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Regressão Logística\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  lr = LogisticRegression()\n",
        "  lr.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Regressão Logística\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", lr.score(X_train, y_train))\n",
        "  tp_lr = lr.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_lr))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_lr))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_lr)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Armazena os resultados em um dicionário\n",
        "  resultados[nome] = {\n",
        "        'Árvore de Decisão': {\n",
        "            'Acurácia Treinamento': tree_custo.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, y_pred)\n",
        "        },\n",
        "        'Naive Bayes': {\n",
        "            'Acurácia Treinamento': nb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_nb)\n",
        "        },\n",
        "        'Gradiente Descendente': {\n",
        "            'Acurácia Treinamento': sgd.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_sgd)\n",
        "        },\n",
        "        'KNN': {\n",
        "            'Acurácia Treinamento': knn.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_knn)\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'Acurácia Treinamento': rfm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_rfm)\n",
        "        },\n",
        "        'SVC': {\n",
        "            'Acurácia Treinamento': svm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_svm)\n",
        "        },\n",
        "        'GradientBoostingClassifier': {\n",
        "            'Acurácia Treinamento': gb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_gb)\n",
        "        },\n",
        "        'AdaBoostClassifier': {\n",
        "            'Acurácia Treinamento': ada.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_ada)\n",
        "        },\n",
        "        'ExtraTreesClassifier': {\n",
        "            'Acurácia Treinamento': et.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_et)\n",
        "        },\n",
        "        'Regressão Logística': {\n",
        "            'Acurácia Treinamento': lr.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_lr)\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "# Criar e exibir as tabelas de resultados\n",
        "for nome, resultados_mesorregiao in resultados.items():\n",
        "    print(f'Análise da Mesorregião: {nome}\\n')\n",
        "    df_resultados = pd.DataFrame.from_dict(resultados_mesorregiao, orient='index')\n",
        "    print(df_resultados)\n",
        "    print('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY8U47vXsTGs"
      },
      "source": [
        "### Anual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9vOm2MOQ-aT"
      },
      "outputs": [],
      "source": [
        "# Função para Áreas Municipais\n",
        "def func_area(x):\n",
        "  if x <= 2700:\n",
        "    return 'Faixa 1'\n",
        "  elif x <= 5350:\n",
        "    return 'Faixa 2'\n",
        "  elif x <= 8630:\n",
        "    return 'Faixa 3'\n",
        "  else:\n",
        "    return 'Faixa 4'\n",
        "\n",
        "# Funções para Faixas de Custeio\n",
        "# Anual\n",
        "def func_faixa_a(x):\n",
        "  if x <= 600000:\n",
        "    return 1\n",
        "  elif x <= 3000000:\n",
        "    return 5\n",
        "  else:\n",
        "    return 15\n",
        "\n",
        "\n",
        "# Preparação das bases\n",
        "custeio_ma = custeio.copy()\n",
        "ibge_ma = ibge.copy()\n",
        "area_ma = area.copy()\n",
        "\n",
        "# Soma de VlCusteio por município por ano\n",
        "custeio_ma_s = custeio_ma.groupby(['Municipio', 'nomeProduto', 'AnoEmissao', 'cdEstado', 'codIbge'], as_index=False)['VlCusteio'].sum()\n",
        "\n",
        "# Escolha do estado (MG = 12), seleção dos objetos e filtragem da base custeio\n",
        "custeio_ma_mg = custeio_ma_s[custeio_ma_s['cdEstado'] == 12]\n",
        "valores_desejados = ['\"BOVINOS\"','\"CAFÉ\"', '\"MILHO\"', '\"SOJA\"']\n",
        "custeio_ma_mg_prod = custeio_ma_mg[custeio_ma_mg['nomeProduto'].isin(valores_desejados)]\n",
        "anos = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "custeio_ma_mg_prod = custeio_ma_mg_prod[custeio_ma_mg_prod['AnoEmissao'].isin(anos)]\n",
        "\n",
        "# Merge das bases de dados\n",
        "custeio_ma_mg_prod_ibge = pd.merge(custeio_ma_mg_prod, ibge_ma, how = 'left')\n",
        "custeio_ma_mg_prod_ibge_area = pd.merge(custeio_ma_mg_prod_ibge, area_ma, how = 'left')\n",
        "\n",
        "# Seleção das colunas\n",
        "custeio_ma_mg_prod_ibge_area_2 = custeio_ma_mg_prod_ibge_area[['nomeProduto',\t'Nome_Mesorregião', 'Nome_Microrregião','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "# Utilização das faixas de valores de custeio\n",
        "custeio_ma_mg_prod_ibge_area_2['VlCusteio'] = custeio_ma_mg_prod_ibge_area_2['VlCusteio'].apply(func_faixa_a)\n",
        "\n",
        "# Identificação dos nomes das mesorregiões\n",
        "meso = custeio_ma_mg_prod_ibge_area_2['Nome_Mesorregião'].unique()\n",
        "\n",
        "for nome in meso:\n",
        "  print('--------------------------------------------------------------------------------')\n",
        "  print(f'Análise da Mesorregiao: ',nome)\n",
        "\n",
        "  # Zona da Mata\n",
        "  custeio_ma_mg_prod_ibge_area_3 = custeio_ma_mg_prod_ibge_area_2[custeio_ma_mg_prod_ibge_area_2['Nome_Mesorregião'] == nome]\n",
        "\n",
        "  # Identificação das Microrregiões de cada Mesorregião\n",
        "  micro = custeio_ma_mg_prod_ibge_area_3['Nome_Microrregião'].unique()\n",
        "  print(f'Essa Mesorregiao é formada por {len(micro)} Microrregiões: ',micro)\n",
        "\n",
        "  # Selecionar colunas\n",
        "  custeio_ma_mg_prod_ibge_area_3 = custeio_ma_mg_prod_ibge_area_3[['nomeProduto', 'Nome_Microrregião','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "  # Gera a lista de variáveis categóricas\n",
        "  cols_cat_ma = custeio_ma_mg_prod_ibge_area_3.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "  # Criação das colunas de Dummies\n",
        "  data_ma = pd.get_dummies(custeio_ma_mg_prod_ibge_area_3, columns=cols_cat_ma, drop_first=True)\n",
        "\n",
        "  # Definição das variáveis dependentes e independentes\n",
        "  X, y = data_ma.drop(['VlCusteio'], axis=1), data_ma['VlCusteio']\n",
        "  class_names = data_ma['VlCusteio']\n",
        "\n",
        "  # Particiona a base de dados\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
        "\n",
        "  # Árvore de Decisão\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "  tree_custo = tree_custo.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo de Árvore de Decisão - DecisionTreeClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento):\", tree_custo.score(X_train, y_train))\n",
        "  y_pred = tree_custo.predict(X_test)\n",
        "  print(\"Acurácia de previsão:\", accuracy_score(y_test, y_pred))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Naive Bayes\n",
        "  from sklearn.naive_bayes import GaussianNB\n",
        "  nb = GaussianNB()\n",
        "  b = nb.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo de Naive Bayes - GaussianNB\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", nb.score(X_train, y_train))\n",
        "  tp_nb = nb.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_nb))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_nb))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_nb)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando Gradiente Descendente\n",
        "  from sklearn.linear_model import SGDClassifier\n",
        "  sgd = SGDClassifier()\n",
        "  sgd = sgd.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Gradiente Descendente - SGDClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", sgd.score(X_train, y_train))\n",
        "  tp_sgd = sgd.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_sgd))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_sgd))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_sgd)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando KNN (K - Nearest Neighbors)\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn = knn.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo KNN (K - Nearest Neighbors) - KNeighborsClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", knn.score(X_train, y_train))\n",
        "  tp_knn = knn.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_knn))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_knn))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_knn)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando Randon Forest\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  rfm = RandomForestClassifier()\n",
        "  rfm = rfm.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Randon Forest - RandomForestClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", rfm.score(X_train, y_train))\n",
        "  tp_rfm = rfm.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_rfm))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_rfm))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_rfm)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo SVC\n",
        "  from sklearn.svm import SVC\n",
        "  svm = SVC()\n",
        "  svm.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo SVC - Support Vector Classification\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", svm.score(X_train, y_train))\n",
        "  tp_svm = svm.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_svm))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_svm))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_svm)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # GradientBoostingClassifier\n",
        "  from sklearn.ensemble import GradientBoostingClassifier\n",
        "  gb = GradientBoostingClassifier()\n",
        "  gb.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo GradientBoostingClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", gb.score(X_train, y_train))\n",
        "  tp_gb = gb.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_gb))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_gb))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_gb)\n",
        "  nf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo AdaBoostClassifier\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "  ada = AdaBoostClassifier()\n",
        "  ada.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo AdaBoostClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", ada.score(X_train, y_train))\n",
        "  tp_ada = ada.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_ada))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_ada))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_ada)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo ExtraTreesClassifier\n",
        "  from sklearn.ensemble import ExtraTreesClassifier\n",
        "  et = ExtraTreesClassifier()\n",
        "  et.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo ExtraTreesClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", et.score(X_train, y_train))\n",
        "  tp_et = et.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_et))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_et))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_et)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Regressão Logística\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  lr = LogisticRegression()\n",
        "  lr.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo ExtraTreesClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", lr.score(X_train, y_train))\n",
        "  tp_lr = lr.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_lr))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_lr))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_lr)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Armazena os resultados em um dicionário\n",
        "  resultados[nome] = {\n",
        "        'Árvore de Decisão': {\n",
        "            'Acurácia Treinamento': tree_custo.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, y_pred)\n",
        "        },\n",
        "        'Naive Bayes': {\n",
        "            'Acurácia Treinamento': nb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_nb)\n",
        "        },\n",
        "        'Gradiente Descendente': {\n",
        "            'Acurácia Treinamento': sgd.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_sgd)\n",
        "        },\n",
        "        'KNN': {\n",
        "            'Acurácia Treinamento': knn.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_knn)\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'Acurácia Treinamento': rfm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_rfm)\n",
        "        },\n",
        "        'SVC': {\n",
        "            'Acurácia Treinamento': svm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_svm)\n",
        "        },\n",
        "        'GradientBoostingClassifier': {\n",
        "            'Acurácia Treinamento': gb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_gb)\n",
        "        },\n",
        "        'AdaBoostClassifier': {\n",
        "            'Acurácia Treinamento': ada.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_ada)\n",
        "        },\n",
        "        'ExtraTreesClassifier': {\n",
        "            'Acurácia Treinamento': et.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_et)\n",
        "        },\n",
        "        'Regressão Logística': {\n",
        "            'Acurácia Treinamento': lr.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_lr)\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "# Criar e exibir as tabelas de resultados\n",
        "for nome, resultados_mesorregiao in resultados.items():\n",
        "    print(f'Análise da Mesorregião: {nome}\\n')\n",
        "    df_resultados = pd.DataFrame.from_dict(resultados_mesorregiao, orient='index')\n",
        "    print(df_resultados)\n",
        "    print('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_d-0xlrLSj0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfbNTVgKdlXd"
      },
      "source": [
        "### Trimestral com Seleção de Produtos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuJ3FhSId5lG"
      },
      "outputs": [],
      "source": [
        "# Função Trimestral\n",
        "def func_trimestre(x):\n",
        "  if x == 1:\n",
        "    return \"primeiro\"\n",
        "  elif x == 2:\n",
        "    return \"primeiro\"\n",
        "  elif x == 3:\n",
        "    return \"primeiro\"\n",
        "  elif x == 4:\n",
        "    return \"segundo\"\n",
        "  elif x == 5:\n",
        "    return \"segundo\"\n",
        "  elif x == 6:\n",
        "    return \"segundo\"\n",
        "  elif x == 7:\n",
        "    return \"terceiro\"\n",
        "  elif x == 8:\n",
        "    return \"terceiro\"\n",
        "  elif x == 9:\n",
        "    return \"terceiro\"\n",
        "  else:\n",
        "    return \"quarto\"\n",
        "\n",
        "\n",
        "# Funções para Faixas de Custeio\n",
        "# Trimestral\n",
        "def func_faixa_t(x):\n",
        "  if x <= 125000:\n",
        "    return 1\n",
        "  elif x <= 750000:\n",
        "    return 10\n",
        "  else:\n",
        "    return 15\n",
        "\n",
        "\n",
        "# Preparação das bases\n",
        "custeio_mt = custeio.copy()\n",
        "ibge_mt = ibge.copy()\n",
        "area_mt = area.copy()\n",
        "\n",
        "# Aplicação da funcão trimestral\n",
        "custeio_mt['Trimestre'] = custeio_mt['MesEmissao'].apply(func_trimestre)\n",
        "\n",
        "# Soma de VlCusteio por município por trimestre\n",
        "custeio_mt_s = custeio_mt.groupby(['Municipio', 'nomeProduto', 'AnoEmissao','Trimestre', 'cdEstado', 'codIbge'], as_index=False)['VlCusteio'].sum()\n",
        "\n",
        "# Escolha do estado (MG = 12), seleção dos objetos e filtragem da base custeio\n",
        "custeio_mt_mg = custeio_mt_s[custeio_mt_s['cdEstado'] == 12]\n",
        "\n",
        "anos = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "custeio_mt_mg = custeio_mt_mg[custeio_mt_mg['AnoEmissao'].isin(anos)]\n",
        "\n",
        "# Merge das bases de dados\n",
        "custeio_mt_mg_ibge = pd.merge(custeio_mt_mg, ibge_mt, how = 'left')\n",
        "custeio_mt_mg_ibge_area = pd.merge(custeio_mt_mg_ibge, area_mt, how = 'left')\n",
        "\n",
        "# Seleção das colunas\n",
        "custeio_mt_mg_ibge_area_2 = custeio_mt_mg_ibge_area[['nomeProduto',\t'Nome_Mesorregião', 'Nome_Microrregião', 'AnoEmissao', 'Trimestre','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "# Utilização das faixas de valores de custeio\n",
        "custeio_mt_mg_ibge_area_2['VlCusteio'] = custeio_mt_mg_ibge_area_2['VlCusteio'].apply(func_faixa_t)\n",
        "\n",
        "# Identificação dos nomes das mesorregiões\n",
        "meso = custeio_mt_mg_ibge_area_2['Nome_Mesorregião'].unique()\n",
        "\n",
        "# Criação de um dicionário para armazenar os resultados\n",
        "resultados = {}\n",
        "\n",
        "for nome in meso:\n",
        "  print('--------------------------------------------------------------------------------')\n",
        "  print(f'Análise da Mesorregiao: {nome}')\n",
        "\n",
        "  # Escolha da mesorregião\n",
        "  custeio_mt_mg_ibge_area_3 = custeio_mt_mg_ibge_area_2[custeio_mt_mg_ibge_area_2['Nome_Mesorregião'] == nome]\n",
        "\n",
        "  # Identificação das Microrregiões de cada Mesorregião\n",
        "  micro = custeio_mt_mg_ibge_area_3['Nome_Microrregião'].unique()\n",
        "  print(f'Essa Mesorregiao é formada por {len(micro)} Microrregiões: {micro}')\n",
        "\n",
        "  # Verificar soma de contratos por produtos para a mesorregião\n",
        "  custeio_mt_mg_ibge_area_3_s = custeio_mt_mg_ibge_area_3.groupby(['nomeProduto'])['VlCusteio'].sum()\n",
        "\n",
        "  # Obter os quatro principais produtos para a mesorregião\n",
        "  custeio_top_products = custeio_mt_mg_ibge_area_3_s.nlargest(4).reset_index()\n",
        "  print(f'Essa mesorregião tem os 4 maiores valores de custeio para os seguintes produtos: ')\n",
        "  print(custeio_top_products['nomeProduto'].tolist())\n",
        "  selecionados = custeio_top_products['nomeProduto'].tolist()\n",
        "\n",
        "  # Filtrar os dados para incluir apenas os 4 produtos com maior VlCusteio\n",
        "  custeio_mt_mg_prod_ibge_area_3 = custeio_mt_mg_ibge_area_3[custeio_mt_mg_ibge_area_3['nomeProduto'].isin(selecionados)]\n",
        "\n",
        "  # Selecionar colunas\n",
        "  custeio_mt_mg_prod_ibge_area_3 = custeio_mt_mg_prod_ibge_area_3[['nomeProduto', 'Nome_Microrregião', 'Trimestre','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "  # Gera a lista de variáveis categóricas\n",
        "  cols_cat_mt = custeio_mt_mg_prod_ibge_area_3.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "  # Criação das colunas de Dummies\n",
        "  data_mt = pd.get_dummies(custeio_mt_mg_prod_ibge_area_3, columns=cols_cat_mt, drop_first=True)\n",
        "\n",
        "  # Definição das variáveis dependentes e independentes\n",
        "  X, y = data_mt.drop(['VlCusteio'], axis=1), data_mt['VlCusteio']\n",
        "  class_names = data_mt['VlCusteio']\n",
        "\n",
        "  # Particiona a base de dados\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
        "\n",
        "  # Árvore de Decisão\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "  tree_custo = tree_custo.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo de Árvore de Decisão - DecisionTreeClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento):\", tree_custo.score(X_train, y_train))\n",
        "  y_pred = tree_custo.predict(X_test)\n",
        "  print(\"Acurácia de previsão:\", accuracy_score(y_test, y_pred))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Naive Bayes\n",
        "  from sklearn.naive_bayes import GaussianNB\n",
        "  nb = GaussianNB()\n",
        "  b = nb.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo de Naive Bayes - GaussianNB\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", nb.score(X_train, y_train))\n",
        "  tp_nb = nb.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_nb))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_nb))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_nb)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando Gradiente Descendente\n",
        "  from sklearn.linear_model import SGDClassifier\n",
        "  sgd = SGDClassifier()\n",
        "  sgd = sgd.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Gradiente Descendente - SGDClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", sgd.score(X_train, y_train))\n",
        "  tp_sgd = sgd.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_sgd))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_sgd))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_sgd)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando KNN (K - Nearest Neighbors)\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn = knn.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo KNN (K - Nearest Neighbors) - KNeighborsClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", knn.score(X_train, y_train))\n",
        "  tp_knn = knn.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_knn))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_knn))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_knn)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando Randon Forest\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  rfm = RandomForestClassifier()\n",
        "  rfm = rfm.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Randon Forest - RandomForestClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", rfm.score(X_train, y_train))\n",
        "  tp_rfm = rfm.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_rfm))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_rfm))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_rfm)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_mt['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo SVC\n",
        "  from sklearn.svm import SVC\n",
        "  svm = SVC()\n",
        "  svm.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo SVC - Support Vector Classification\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", svm.score(X_train, y_train))\n",
        "  tp_svm = svm.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_svm))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_svm))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_svm)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # GradientBoostingClassifier\n",
        "  from sklearn.ensemble import GradientBoostingClassifier\n",
        "  gb = GradientBoostingClassifier()\n",
        "  gb.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo GradientBoostingClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", gb.score(X_train, y_train))\n",
        "  tp_gb = gb.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_gb))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_gb))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_gb)\n",
        "  nf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo AdaBoostClassifier\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "  ada = AdaBoostClassifier()\n",
        "  ada.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo AdaBoostClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", ada.score(X_train, y_train))\n",
        "  tp_ada = ada.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_ada))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_ada))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_ada)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo ExtraTreesClassifier\n",
        "  from sklearn.ensemble import ExtraTreesClassifier\n",
        "  et = ExtraTreesClassifier()\n",
        "  et.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo ExtraTreesClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", et.score(X_train, y_train))\n",
        "  tp_et = et.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_et))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_et))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_et)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Regressão Logística\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  lr = LogisticRegression()\n",
        "  lr.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Regressão Logística\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", lr.score(X_train, y_train))\n",
        "  tp_lr = lr.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_lr))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_lr))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_lr)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_mt['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_mt['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Armazena os resultados em um dicionário\n",
        "  resultados[nome] = {\n",
        "        'Árvore de Decisão': {\n",
        "            'Acurácia Treinamento': tree_custo.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, y_pred)\n",
        "        },\n",
        "        'Naive Bayes': {\n",
        "            'Acurácia Treinamento': nb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_nb)\n",
        "        },\n",
        "        'Gradiente Descendente': {\n",
        "            'Acurácia Treinamento': sgd.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_sgd)\n",
        "        },\n",
        "        'KNN': {\n",
        "            'Acurácia Treinamento': knn.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_knn)\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'Acurácia Treinamento': rfm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_rfm)\n",
        "        },\n",
        "        'SVC': {\n",
        "            'Acurácia Treinamento': svm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_svm)\n",
        "        },\n",
        "        'GradientBoostingClassifier': {\n",
        "            'Acurácia Treinamento': gb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_gb)\n",
        "        },\n",
        "        'AdaBoostClassifier': {\n",
        "            'Acurácia Treinamento': ada.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_ada)\n",
        "        },\n",
        "        'ExtraTreesClassifier': {\n",
        "            'Acurácia Treinamento': et.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_et)\n",
        "        },\n",
        "        'Regressão Logística': {\n",
        "            'Acurácia Treinamento': lr.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_lr)\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "# Criar e exibir as tabelas de resultados\n",
        "for nome, resultados_mesorregiao in resultados.items():\n",
        "    print(f'Análise da Mesorregião: {nome}\\n')\n",
        "    df_resultados = pd.DataFrame(resultados_mesorregiao).T\n",
        "    print(df_resultados)\n",
        "    print('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP6wwejNQ1Kq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqAhDcPILTZl"
      },
      "source": [
        "### Anual com Seleção de Produtos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6ONOMQdLTZn"
      },
      "outputs": [],
      "source": [
        "# Funções para Faixas de Custeio\n",
        "# Anual\n",
        "def func_faixa_a(x):\n",
        "  if x <= 600000:\n",
        "    return 1\n",
        "  elif x <= 3000000:\n",
        "    return 5\n",
        "  else:\n",
        "    return 15\n",
        "\n",
        "\n",
        "# Preparação das bases\n",
        "custeio_ma = custeio.copy()\n",
        "ibge_ma = ibge.copy()\n",
        "area_ma = area.copy()\n",
        "\n",
        "# Soma de VlCusteio por município por ano\n",
        "custeio_ma_s = custeio_ma.groupby(['Municipio', 'nomeProduto', 'AnoEmissao', 'cdEstado', 'codIbge'], as_index=False)['VlCusteio'].sum()\n",
        "\n",
        "# Escolha do estado (MG = 12), seleção dos objetos e filtragem da base custeio\n",
        "custeio_ma_mg = custeio_ma_s[custeio_ma_s['cdEstado'] == 12]\n",
        "\n",
        "anos = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "custeio_ma_mg = custeio_ma_mg[custeio_ma_mg['AnoEmissao'].isin(anos)]\n",
        "\n",
        "# Merge das bases de dados\n",
        "custeio_ma_mg_ibge = pd.merge(custeio_ma_mg, ibge_ma, how = 'left')\n",
        "custeio_ma_mg_ibge_area = pd.merge(custeio_ma_mg_ibge, area_ma, how = 'left')\n",
        "\n",
        "# Seleção das colunas\n",
        "custeio_ma_mg_ibge_area_2 = custeio_ma_mg_ibge_area[['nomeProduto',\t'Nome_Mesorregião', 'Nome_Microrregião', 'AnoEmissao','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "# Utilização das faixas de valores de custeio\n",
        "custeio_ma_mg_ibge_area_2['VlCusteio'] = custeio_ma_mg_ibge_area_2['VlCusteio'].apply(func_faixa_a)\n",
        "\n",
        "# Identificação dos nomes das mesorregiões\n",
        "meso = custeio_ma_mg_ibge_area_2['Nome_Mesorregião'].unique()\n",
        "\n",
        "# Criação de um dicionário para armazenar os resultados\n",
        "resultados = {}\n",
        "\n",
        "for nome in meso:\n",
        "  print('--------------------------------------------------------------------------------')\n",
        "  print(f'Análise da Mesorregiao: ',nome)\n",
        "\n",
        "  # Mesorregiões\n",
        "  custeio_ma_mg_ibge_area_3 = custeio_ma_mg_ibge_area_2[custeio_ma_mg_ibge_area_2['Nome_Mesorregião'] == nome]\n",
        "\n",
        "  # Identificação das Microrregiões de cada Mesorregião\n",
        "  micro = custeio_ma_mg_ibge_area_3['Nome_Microrregião'].unique()\n",
        "  print(f'Essa Mesorregiao é formada por {len(micro)} Microrregiões: ',micro)\n",
        "\n",
        "  # Verificar soma de contratos por produtos para a mesorregião\n",
        "  custeio_ma_mg_ibge_area_3_s = custeio_ma_mg_ibge_area_3.groupby(['nomeProduto'])['VlCusteio'].sum()\n",
        "\n",
        "  # Obter os quatro principais produtos para a mesorregião\n",
        "  custeio_top_products = custeio_ma_mg_ibge_area_3_s.nlargest(4).reset_index()\n",
        "  print(f'Essa mesorregião tem os 4 maiores valores de custeio para os seguintes produtos: ')\n",
        "  print(custeio_top_products['nomeProduto'].tolist())\n",
        "  selecionados = custeio_top_products['nomeProduto'].tolist()\n",
        "\n",
        "  # Filtrar os dados para incluir apenas os 10 produtos com maior VlCusteio\n",
        "  custeio_ma_mg_prod_ibge_area_3 = custeio_ma_mg_ibge_area_3[custeio_ma_mg_ibge_area_3['nomeProduto'].isin(selecionados)]\n",
        "\n",
        "  # Selecionar colunas\n",
        "  custeio_ma_mg_prod_ibge_area_3 = custeio_ma_mg_prod_ibge_area_3[['nomeProduto', 'Nome_Microrregião','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "  # Gera a lista de variáveis categóricas\n",
        "  cols_cat_ma = custeio_ma_mg_prod_ibge_area_3.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "  # Criação das colunas de Dummies\n",
        "  data_ma = pd.get_dummies(custeio_ma_mg_prod_ibge_area_3, columns=cols_cat_ma, drop_first=True)\n",
        "\n",
        "  # Definição das variáveis dependentes e independentes\n",
        "  X, y = data_ma.drop(['VlCusteio'], axis=1), data_ma['VlCusteio']\n",
        "  class_names = data_ma['VlCusteio']\n",
        "\n",
        "  # Particiona a base de dados\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
        "\n",
        "  # Árvore de Decisão\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "  tree_custo = tree_custo.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo de Árvore de Decisão - DecisionTreeClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento):\", tree_custo.score(X_train, y_train))\n",
        "  y_pred = tree_custo.predict(X_test)\n",
        "  print(\"Acurácia de previsão:\", accuracy_score(y_test, y_pred))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, y_pred))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Naive Bayes\n",
        "  from sklearn.naive_bayes import GaussianNB\n",
        "  nb = GaussianNB()\n",
        "  b = nb.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo de Naive Bayes - GaussianNB\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", nb.score(X_train, y_train))\n",
        "  tp_nb = nb.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_nb))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_nb))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_nb)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando Gradiente Descendente\n",
        "  from sklearn.linear_model import SGDClassifier\n",
        "  sgd = SGDClassifier()\n",
        "  sgd = sgd.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Gradiente Descendente - SGDClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", sgd.score(X_train, y_train))\n",
        "  tp_sgd = sgd.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_sgd))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_sgd))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_sgd)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando KNN (K - Nearest Neighbors)\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  knn = KNeighborsClassifier()\n",
        "  knn = knn.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo KNN (K - Nearest Neighbors) - KNeighborsClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", knn.score(X_train, y_train))\n",
        "  tp_knn = knn.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_knn))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_knn))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_knn)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  #Criação do modelo utilizando Randon Forest\n",
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  rfm = RandomForestClassifier()\n",
        "  rfm = rfm.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo Randon Forest - RandomForestClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", rfm.score(X_train, y_train))\n",
        "  tp_rfm = rfm.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_rfm))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_rfm))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_rfm)\n",
        "  cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo SVC\n",
        "  from sklearn.svm import SVC\n",
        "  svm = SVC()\n",
        "  svm.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo SVC - Support Vector Classification\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", svm.score(X_train, y_train))\n",
        "  tp_svm = svm.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_svm))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_svm))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_svm)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # GradientBoostingClassifier\n",
        "  from sklearn.ensemble import GradientBoostingClassifier\n",
        "  gb = GradientBoostingClassifier()\n",
        "  gb.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo GradientBoostingClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", gb.score(X_train, y_train))\n",
        "  tp_gb = gb.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_gb))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_gb))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_gb)\n",
        "  nf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo AdaBoostClassifier\n",
        "  from sklearn.ensemble import AdaBoostClassifier\n",
        "  ada = AdaBoostClassifier()\n",
        "  ada.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo AdaBoostClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", ada.score(X_train, y_train))\n",
        "  tp_ada = ada.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_ada))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_ada))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_ada)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Modelo ExtraTreesClassifier\n",
        "  from sklearn.ensemble import ExtraTreesClassifier\n",
        "  et = ExtraTreesClassifier()\n",
        "  et.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo ExtraTreesClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", et.score(X_train, y_train))\n",
        "  tp_et = et.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_et))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_et))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_et)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Regressão Logística\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  lr = LogisticRegression()\n",
        "  lr.fit(X_train, y_train)\n",
        "  print(\"\")\n",
        "  print(\"Modelo ExtraTreesClassifier\")\n",
        "  print(\"\")\n",
        "  print(\"Dados de Acurácia\")\n",
        "  print(\"Acurácia (base de treinamento): \", lr.score(X_train, y_train))\n",
        "  tp_lr = lr.predict(X_test)\n",
        "  print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_lr))\n",
        "  print(\"\")\n",
        "  print(\"Classification Report:\")\n",
        "  print(\"\")\n",
        "  print(classification_report(y_test, tp_lr))\n",
        "  print(\"\")\n",
        "  print(\"Matriz de Confusão:\")\n",
        "  print(\"\")\n",
        "  cnf_matrix = confusion_matrix(y_test, tp_lr)\n",
        "  cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "  print(cnf_table)\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "\n",
        "  # Armazena os resultados em um dicionário\n",
        "  resultados[nome] = {\n",
        "        'Árvore de Decisão': {\n",
        "            'Acurácia Treinamento': tree_custo.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, y_pred)\n",
        "        },\n",
        "        'Naive Bayes': {\n",
        "            'Acurácia Treinamento': nb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_nb)\n",
        "        },\n",
        "        'Gradiente Descendente': {\n",
        "            'Acurácia Treinamento': sgd.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_sgd)\n",
        "        },\n",
        "        'KNN': {\n",
        "            'Acurácia Treinamento': knn.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_knn)\n",
        "        },\n",
        "        'Random Forest': {\n",
        "            'Acurácia Treinamento': rfm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_rfm)\n",
        "        },\n",
        "        'SVC': {\n",
        "            'Acurácia Treinamento': svm.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_svm)\n",
        "        },\n",
        "        'GradientBoostingClassifier': {\n",
        "            'Acurácia Treinamento': gb.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_gb)\n",
        "        },\n",
        "        'AdaBoostClassifier': {\n",
        "            'Acurácia Treinamento': ada.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_ada)\n",
        "        },\n",
        "        'ExtraTreesClassifier': {\n",
        "            'Acurácia Treinamento': et.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_et)\n",
        "        },\n",
        "        'Regressão Logística': {\n",
        "            'Acurácia Treinamento': lr.score(X_train, y_train),\n",
        "            'Acurácia Teste': accuracy_score(y_test, tp_lr)\n",
        "        }\n",
        "\n",
        "    }\n",
        "\n",
        "# Criar e exibir as tabelas de resultados\n",
        "for nome, resultados_mesorregiao in resultados.items():\n",
        "    print(f'Análise da Mesorregião: {nome}\\n')\n",
        "    df_resultados = pd.DataFrame(resultados_mesorregiao).T\n",
        "    print(df_resultados)\n",
        "    print('\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmaYclAuLSup"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtAr7ohjbPhm"
      },
      "source": [
        "## Previsões"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX10NClCReWz"
      },
      "source": [
        "### Previsões para modelos do tipo Trimestral (Sem 'AnoEmissao')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQzNhGoiSjQ4"
      },
      "outputs": [],
      "source": [
        "X_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ytqgHLoSjQ4"
      },
      "outputs": [],
      "source": [
        "# A última mesorregião avaliada no modelo acima foi a Norte de Minas\n",
        "## 'nomeProduto': dummie ['\"BOVINOS\"', '\"CAFÉ\"', '\"BANANA\"', '\"SOJA\"']\n",
        "## 'Nome_Microrregião': dummie\n",
        "## 'AR_MUN_2022': número real positivo\n",
        "\n",
        "\"\"\"\n",
        "Órdem das colunas em X_train:\n",
        "\n",
        "\n",
        "AR_MUN_2022\n",
        "\n",
        "\n",
        "nomeProduto_\"CAFÉ\"\n",
        "nomeProduto_\"MILHO\"\n",
        "nomeProduto_\"SOJA\"\n",
        "\n",
        "\n",
        "Nome_Mesorregião_Central Mineira\n",
        "Nome_Mesorregião_Jequitinhonha\n",
        "Nome_Mesorregião_Metropolitana de Belo Horizonte\n",
        "Nome_Mesorregião_Noroeste de Minas\n",
        "Nome_Mesorregião_Norte de Minas\n",
        "Nome_Mesorregião_Oeste de Minas\n",
        "Nome_Mesorregião_Sul/Sudoeste de Minas\n",
        "Nome_Mesorregião_Triângulo Mineiro/Alto Paranaíba\n",
        "Nome_Mesorregião_Vale do Mucuri\n",
        "Nome_Mesorregião_Vale do Rio Doce\n",
        "Nome_Mesorregião_Zona da Mata\n",
        "\n",
        "\n",
        "Trimestre_quarto\n",
        "Trimestre_segundo\n",
        "Trimestre_terceiro\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Importar bibliotecas\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "v_prod = ['\"BOVINOS\"','\"CAFÉ\"','\"MILHO\"','\"SOJA\"']\n",
        "v_meso = ['Campo das Vertentes','Central Mineira','Jequitinhonha','Metropolitana de Belo Horizonte','Noroeste de Minas',\n",
        "           'Oeste de Minas','Sul/Sudoeste de Minas','Triângulo Mineiro/Alto Paranaíba','Vale do Mucuri',\n",
        "           'Vale do Rio Doce','Zona da Mata']\n",
        "v_trim = ['Primeiro', ' Quarto', 'Segundo', 'Terceiro']\n",
        "\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_meso = v_meso[1]\n",
        "valor_trimestre = v_trim[1]\n",
        "\n",
        "\n",
        "# Árvore de Decisão\n",
        "previsao_tree_custo = tree_custo.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Arvore de Decisão na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_tree_custo}\\n\\n')\n",
        "\n",
        "# Naive Bayes\n",
        "previsao_nb = nb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Naive Bayes na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_nb}\\n\\n')\n",
        "\n",
        "# Gradiente Descendente\n",
        "previsao_sgd = sgd.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Gradiente Descendente na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_sgd}\\n\\n')\n",
        "\n",
        "# KNN (K - Nearest Neighbors)\n",
        "previsao_knn = knn.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para K - Nearest Neighbors na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_knn}\\n\\n')\n",
        "\n",
        "# Random Forest\n",
        "previsao_rfm = rfm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Random Forest na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_rfm}\\n\\n')\n",
        "\n",
        "# SVC (Support Vector Classification)\n",
        "previsao_svm = svm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Support Vector Classification na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_svm}\\n\\n')\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "previsao_gb = gb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Gradient Boosting Classifier na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_gb}\\n\\n')\n",
        "\n",
        "# AdaBoost Classifier\n",
        "previsao_ada = ada.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para AdaBoost Classifier na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_ada}\\n\\n')\n",
        "\n",
        "# Extra Trees Classifier\n",
        "previsao_et = et.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Extra Trees Classifier na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_et}\\n\\n')\n",
        "\n",
        "# Regressão Logística\n",
        "previsao_lr = lr.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Regressão Logística na mesorregião {valor_meso}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_lr}\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_hMihSaSjQ5"
      },
      "outputs": [],
      "source": [
        "# Obter os nomes das colunas\n",
        "colunas = X_train.columns\n",
        "\n",
        "# Criar um dicionário para mapear os valores\n",
        "valores = [4000,1,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0]\n",
        "valores_mapeados = dict(zip(colunas, valores))\n",
        "\n",
        "# Obter as colunas correspondentes aos valores fornecidos\n",
        "colunas_correspondentes = [coluna for coluna, valor in valores_mapeados.items() if valor != 0]\n",
        "\n",
        "print(colunas_correspondentes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIXIAoHoSitA"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCoVZ6OhmY19"
      },
      "source": [
        "### Previsões para modelos do tipo Anual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RE7J-MVoundR"
      },
      "outputs": [],
      "source": [
        "X_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGGb0XZhbSTm"
      },
      "outputs": [],
      "source": [
        "# A última mesorregião avaliada no modelo acima foi a Norte de Minas\n",
        "## 'nomeProduto': dummie (4)\n",
        "## 'Nome_Mesorregião': dummie (12)\n",
        "## 'AR_MUN_2022': número real positivo\n",
        "\n",
        "'''\n",
        "Órdem das colunas em X_train:\n",
        "\n",
        "AR_MUN_2022\n",
        "\n",
        "nomeProduto_\"CAFÉ\"\n",
        "nomeProduto_\"MILHO\"\n",
        "nomeProduto_\"SOJA\"\n",
        "\n",
        "Nome_Mesorregião_Central Mineira\n",
        "Nome_Mesorregião_Jequitinhonha\n",
        "Nome_Mesorregião_Metropolitana de Belo Horizonte\n",
        "Nome_Mesorregião_Noroeste de Minas\n",
        "Nome_Mesorregião_Norte de Minas\n",
        "Nome_Mesorregião_Oeste de Minas\n",
        "Nome_Mesorregião_Sul/Sudoeste de Minas\n",
        "Nome_Mesorregião_Triângulo Mineiro/Alto Paranaíba\n",
        "Nome_Mesorregião_Vale do Mucuri\n",
        "Nome_Mesorregião_Vale do Rio Doce\n",
        "Nome_Mesorregião_Zona da Mata\n",
        "'''\n",
        "\n",
        "# Importar bibliotecas\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "v_prod = ['\"BOVINOS\"','\"CAFÉ\"','\"MILHO\"','\"SOJA\"']\n",
        "v_meso = ['Campo das Vertentes','Central Mineira','Jequitinhonha','Metropolitana de Belo Horizonte','Noroeste de Minas',\n",
        "           'Norte de Minas','Oeste de Minas','Sul/Sudoeste de Minas','Triângulo Mineiro/Alto Paranaíba','Vale do Mucuri',\n",
        "           'Vale do Rio Doce','Zona da Mata']\n",
        "\n",
        "valores_para_previsao = [[400,0,1,0,0,0,0,1,0,0,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[2]\n",
        "valor_meso = v_meso[4]\n",
        "\n",
        "\n",
        "# Árvore de Decisão\n",
        "previsao_tree_custo = tree_custo.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Arvore de Decisão na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_tree_custo}\\n\\n')\n",
        "\n",
        "# Naive Bayes\n",
        "previsao_nb = nb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Naive Bayes na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_nb}\\n\\n')\n",
        "\n",
        "# Gradiente Descendente\n",
        "previsao_sgd = sgd.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Gradiente Descendente na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_sgd}\\n\\n')\n",
        "\n",
        "# KNN (K - Nearest Neighbors)\n",
        "previsao_knn = knn.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para K - Nearest Neighbors na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_knn}\\n\\n')\n",
        "\n",
        "# Random Forest\n",
        "previsao_rfm = rfm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Random Forest na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_rfm}\\n\\n')\n",
        "\n",
        "# SVC (Support Vector Classification)\n",
        "previsao_svm = svm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Support Vector Classification na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_svm}\\n\\n')\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "previsao_gb = gb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Gradient Boosting Classifier na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_gb}\\n\\n')\n",
        "\n",
        "# AdaBoost Classifier\n",
        "previsao_ada = ada.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para AdaBoost Classifier na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_ada}\\n\\n')\n",
        "\n",
        "# Extra Trees Classifier\n",
        "previsao_et = et.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Extra Trees Classifier na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_et}\\n\\n')\n",
        "\n",
        "# Regressão Logística\n",
        "previsao_lr = lr.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Regressão Logística na mesorregião {valor_meso}, produto {valor_produto} e área de {valor_area} km²: {previsao_lr}\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kpgtiGvbSWt"
      },
      "outputs": [],
      "source": [
        "# Obter os nomes das colunas\n",
        "colunas = X_train.columns\n",
        "\n",
        "# Criar um dicionário para mapear os valores\n",
        "valores = [400,0,1,0,0,0,0,1,0,0,0,0,0,0,0]\n",
        "valores_mapeados = dict(zip(colunas, valores))\n",
        "\n",
        "# Obter as colunas correspondentes aos valores fornecidos\n",
        "colunas_correspondentes = [coluna for coluna, valor in valores_mapeados.items() if valor != 0]\n",
        "\n",
        "print(colunas_correspondentes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KH8PfHnOYySK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83wyoikAYyuh"
      },
      "source": [
        "### Previsões para modelos mesorregionais do tipo Trimestral com seleção de produtos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzWcKZZSZAgq"
      },
      "outputs": [],
      "source": [
        "X_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rht_H1_xZAg1"
      },
      "outputs": [],
      "source": [
        "# A última mesorregião avaliada no modelo acima foi a Norte de Minas\n",
        "## 'nomeProduto': dummie ['\"BOVINOS\"', '\"CAFÉ\"', '\"BANANA\"', '\"SOJA\"']\n",
        "## 'Nome_Microrregião': dummie ['Salinas' 'Bocaiúva' 'Januária' 'Grão Mogol' 'Montes Claros' 'Pirapora'  'Janaúba']\n",
        "## 'AR_MUN_2022': número real positivo\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "Órdem das colunas em X_train:\n",
        "\n",
        "AR_MUN_2022\n",
        "\n",
        "\n",
        "nomeProduto_\"BOVINOS\"\n",
        "nomeProduto_\"CAFÉ\"\n",
        "nomeProduto_\"SOJA\"\n",
        "\n",
        "\n",
        "Nome_Microrregião_Grão Mogol\n",
        "Nome_Microrregião_Janaúba\n",
        "Nome_Microrregião_Januária\n",
        "Nome_Microrregião_Montes Claros\n",
        "Nome_Microrregião_Pirapora\n",
        "Nome_Microrregião_Salinas\n",
        "\n",
        "\n",
        "Trimestre_quarto\n",
        "Trimestre_segundo\n",
        "Trimestre_terceiro\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Importar bibliotecas\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "v_prod = ['\"BANANA\"','\"BOVINOS\"','\"CAFÉ\"','\"SOJA\"']\n",
        "v_micro = ['Bocaiúva','Grão Mogol','Janaúba','Januária','Montes Claros','Pirapora','Salinas']\n",
        "v_trim = ['Primeiro', ' Quarto', 'Segundo', 'Terceiro']\n",
        "\n",
        "valores_para_previsao = [[4000,0,1,0,0,1,0,0,0,0,0,1,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[2]\n",
        "valor_micro = v_micro[2]\n",
        "valor_trimestre = v_trim[2]\n",
        "valor_meso = nome\n",
        "\n",
        "\n",
        "# Árvore de Decisão\n",
        "previsao_tree_custo = tree_custo.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Arvore de Decisão na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_tree_custo}\\n\\n')\n",
        "\n",
        "# Naive Bayes\n",
        "previsao_nb = nb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Naive Bayes na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_nb}\\n\\n')\n",
        "\n",
        "# Gradiente Descendente\n",
        "previsao_sgd = sgd.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Gradiente Descendente na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_sgd}\\n\\n')\n",
        "\n",
        "# KNN (K - Nearest Neighbors)\n",
        "previsao_knn = knn.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para K - Nearest Neighbors na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_knn}\\n\\n')\n",
        "\n",
        "# Random Forest\n",
        "previsao_rfm = rfm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Random Forest na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_rfm}\\n\\n')\n",
        "# SVC (Support Vector Classification)\n",
        "previsao_svm = svm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Support Vector Classification na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_svm}\\n\\n')\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "previsao_gb = gb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Gradient Boosting Classifier na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_gb}\\n\\n')\n",
        "\n",
        "# AdaBoost Classifier\n",
        "previsao_ada = ada.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para AdaBoost Classifier na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_ada}\\n\\n')\n",
        "\n",
        "# Extra Trees Classifier\n",
        "previsao_et = et.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Extra Trees Classifier na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_et}\\n\\n')\n",
        "\n",
        "# Regressão Logística\n",
        "previsao_lr = lr.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Regressão Logística na mesorregião {valor_meso}, microrregião {valor_micro}, {valor_trimestre} trimestre, produto {valor_produto} e área de {valor_area} km²: {previsao_lr}\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "98PhRi2vZAg2"
      },
      "outputs": [],
      "source": [
        "# Obter os nomes das colunas\n",
        "colunas = X_train.columns\n",
        "\n",
        "# Criar um dicionário para mapear os valores\n",
        "valores = [4000,0,1,0,0,1,0,0,0,0,0,1,0]\n",
        "valores_mapeados = dict(zip(colunas, valores))\n",
        "\n",
        "# Obter as colunas correspondentes aos valores fornecidos\n",
        "colunas_correspondentes = [coluna for coluna, valor in valores_mapeados.items() if valor != 0]\n",
        "\n",
        "print(colunas_correspondentes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NTCwJ77Y4x0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gh6qt1x0mMJd"
      },
      "source": [
        "### Previsões para modelos mesorregionais do tipo Anual com seleção de produtos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf--PTAzsFTm"
      },
      "outputs": [],
      "source": [
        "X_train.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-0L_LYChbSQn"
      },
      "outputs": [],
      "source": [
        "# A última mesorregião avaliada no modelo acima foi a Norte de Minas\n",
        "## 'nomeProduto': dummie ['\"BOVINOS\"', '\"CAFÉ\"', '\"BANANA\"', '\"SOJA\"']\n",
        "## 'Nome_Microrregião': dummie ['Salinas' 'Bocaiúva' 'Januária' 'Grão Mogol' 'Montes Claros' 'Pirapora'  'Janaúba']\n",
        "## 'AR_MUN_2022': número real positivo\n",
        "\n",
        "\"\"\"\n",
        "Órdem das colunas em X_train:\n",
        "\n",
        "AR_MUN_2022\n",
        "\n",
        "nomeProduto_\"BOVINOS\"\n",
        "nomeProduto_\"CAFÉ\"\n",
        "nomeProduto_\"SOJA\"\n",
        "\n",
        "Nome_Microrregião_Grão Mogol\n",
        "Nome_Microrregião_Janaúba\n",
        "Nome_Microrregião_Januária\n",
        "Nome_Microrregião_Montes Claros\n",
        "Nome_Microrregião_Pirapora\n",
        "Nome_Microrregião_Salinas\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Importar bibliotecas\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "v_prod = ['\"BANANA\"','\"BOVINOS\"','\"CAFÉ\"','\"SOJA\"']\n",
        "v_micro = ['Bocaiúva','Grão Mogol','Janaúba','Januária','Montes Claros','Pirapora','Salinas']\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "\n",
        "# Árvore de Decisão\n",
        "previsao_tree_custo = tree_custo.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Arvore de Decisão na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_tree_custo}\\n\\n')\n",
        "\n",
        "# Naive Bayes\n",
        "previsao_nb = nb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Naive Bayes na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_nb}\\n\\n')\n",
        "\n",
        "# Gradiente Descendente\n",
        "previsao_sgd = sgd.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Gradiente Descendente na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_sgd}\\n\\n')\n",
        "\n",
        "# KNN (K - Nearest Neighbors)\n",
        "previsao_knn = knn.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para K - Nearest Neighbors na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_knn}\\n\\n')\n",
        "\n",
        "# Random Forest\n",
        "previsao_rfm = rfm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Random Forest na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_rfm}\\n\\n')\n",
        "\n",
        "# SVC (Support Vector Classification)\n",
        "previsao_svm = svm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Support Vector Classification na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_svm}\\n\\n')\n",
        "\n",
        "# Gradient Boosting Classifier\n",
        "previsao_gb = gb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Gradient Boosting Classifier na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_gb}\\n\\n')\n",
        "\n",
        "# AdaBoost Classifier\n",
        "previsao_ada = ada.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para AdaBoost Classifier na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_ada}\\n\\n')\n",
        "\n",
        "# Extra Trees Classifier\n",
        "previsao_et = et.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Extra Trees Classifier na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_et}\\n\\n')\n",
        "\n",
        "# Regressão Logística\n",
        "previsao_lr = lr.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Regressão Logística na mesorregião {nome}, microrregião {valor_micro}, produto {valor_produto} e área de {valor_area} km²: {previsao_lr}\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3tI8Ps9rLcd"
      },
      "outputs": [],
      "source": [
        "# Obter os nomes das colunas\n",
        "colunas = X_train.columns\n",
        "\n",
        "# Criar um dicionário para mapear os valores\n",
        "valores = [400,1,0,0,1,0,0,0,0,0]\n",
        "valores_mapeados = dict(zip(colunas, valores))\n",
        "\n",
        "# Obter as colunas correspondentes aos valores fornecidos\n",
        "colunas_correspondentes = [coluna for coluna, valor in valores_mapeados.items() if valor != 0]\n",
        "\n",
        "print(colunas_correspondentes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSMzv1qBDjZz"
      },
      "source": [
        "## Mesorregião Triângulo Mineiro/Alto Paranaíba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROXFMH76Dn2u"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "# Funções para Faixas de Custeio\n",
        "# Anual\n",
        "def func_faixa_a(x):\n",
        "  if x <= 600000:\n",
        "    return 1\n",
        "  elif x <= 3000000:\n",
        "    return 5\n",
        "  else:\n",
        "    return 15\n",
        "\n",
        "\n",
        "# Preparação das bases\n",
        "custeio_ma = custeio.copy()\n",
        "ibge_ma = ibge.copy()\n",
        "area_ma = area.copy()\n",
        "\n",
        "# Soma de VlCusteio por município por ano\n",
        "custeio_ma_s = custeio_ma.groupby(['Municipio', 'nomeProduto', 'AnoEmissao', 'cdEstado', 'codIbge'], as_index=False)['VlCusteio'].sum()\n",
        "\n",
        "# Escolha do estado (MG = 12), seleção dos objetos e filtragem da base custeio\n",
        "custeio_ma_mg = custeio_ma_s[custeio_ma_s['cdEstado'] == 12]\n",
        "\n",
        "anos = [2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022]\n",
        "custeio_ma_mg = custeio_ma_mg[custeio_ma_mg['AnoEmissao'].isin(anos)]\n",
        "\n",
        "# Merge das bases de dados\n",
        "custeio_ma_mg_ibge = pd.merge(custeio_ma_mg, ibge_ma, how = 'left')\n",
        "custeio_ma_mg_ibge_area = pd.merge(custeio_ma_mg_ibge, area_ma, how = 'left')\n",
        "\n",
        "# Seleção das colunas\n",
        "custeio_ma_mg_ibge_area_2 = custeio_ma_mg_ibge_area[['nomeProduto',\t'Nome_Mesorregião', 'Nome_Microrregião', 'AnoEmissao','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "# Utilização das faixas de valores de custeio\n",
        "custeio_ma_mg_ibge_area_2['VlCusteio'] = custeio_ma_mg_ibge_area_2['VlCusteio'].apply(func_faixa_a)\n",
        "\n",
        "# Mesorregião Triângulo Mineiro/Alto Paranaíba\n",
        "custeio_ma_mg_ibge_area_2 = custeio_ma_mg_ibge_area_2[custeio_ma_mg_ibge_area_2['Nome_Mesorregião'] == 'Triângulo Mineiro/Alto Paranaíba']\n",
        "\n",
        "# Criação de um dicionário para armazenar os resultados\n",
        "resultados = {}\n",
        "\n",
        "print('--------------------------------------------------------------------------------')\n",
        "print('Análise da Mesorregiao Triângulo Mineiro/Alto Paranaíba')\n",
        "\n",
        "# Identificação das Microrregiões de cada Mesorregião\n",
        "micro = custeio_ma_mg_ibge_area_2['Nome_Microrregião'].unique()\n",
        "print(f'Essa Mesorregiao é formada por {len(micro)} Microrregiões: ',micro)\n",
        "\n",
        "# Verificar soma de contratos por produtos para a mesorregião\n",
        "custeio_ma_mg_ibge_area_2_s = custeio_ma_mg_ibge_area_2.groupby(['nomeProduto'])['VlCusteio'].sum()\n",
        "\n",
        "# Obter os quatro principais produtos para a mesorregião\n",
        "custeio_top_products = custeio_ma_mg_ibge_area_2_s.nlargest(4).reset_index()\n",
        "print(f'Essa mesorregião tem os 4 maiores valores de custeio para os seguintes produtos: ')\n",
        "print(custeio_top_products['nomeProduto'].tolist())\n",
        "selecionados = custeio_top_products['nomeProduto'].tolist()\n",
        "\n",
        "# Filtrar os dados para incluir apenas os 10 produtos com maior VlCusteio\n",
        "custeio_ma_mg_prod_ibge_area_2 = custeio_ma_mg_ibge_area_2[custeio_ma_mg_ibge_area_2['nomeProduto'].isin(selecionados)]\n",
        "\n",
        "# Selecionar colunas\n",
        "custeio_ma_mg_prod_ibge_area_2 = custeio_ma_mg_prod_ibge_area_2[['nomeProduto', 'Nome_Microrregião','AR_MUN_2022','VlCusteio']]\n",
        "\n",
        "# Gera a lista de variáveis categóricas\n",
        "cols_cat_ma = custeio_ma_mg_prod_ibge_area_2.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Criação das colunas de Dummies\n",
        "data_ma = pd.get_dummies(custeio_ma_mg_prod_ibge_area_2, columns=cols_cat_ma, drop_first=True)\n",
        "\n",
        "# Definição das variáveis dependentes e independentes\n",
        "X, y = data_ma.drop(['VlCusteio'], axis=1), data_ma['VlCusteio']\n",
        "class_names = data_ma['VlCusteio']\n",
        "\n",
        "# Particiona a base de dados\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P7gHkkKa7ucK"
      },
      "outputs": [],
      "source": [
        "# Árvore de Decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree_custo = DecisionTreeClassifier(random_state=0, criterion='log_loss')\n",
        "tree_custo = tree_custo.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo de Árvore de Decisão - DecisionTreeClassifier\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento):\", tree_custo.score(X_train, y_train))\n",
        "y_pred = tree_custo.predict(X_test)\n",
        "print(\"Acurácia de previsão:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(tree_custo, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcf56Ix281A6"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5k4ILtkP9TkA"
      },
      "outputs": [],
      "source": [
        "# Árvore de Decisão\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "\n",
        "previsao_tree_custo = tree_custo.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Arvore de Decisão na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_tree_custo}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7IzSWX5I8Hp"
      },
      "outputs": [],
      "source": [
        "# Árvore de Decisão\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[10000,0,0,0,0,1,0,0,0,0]]\n",
        "valor_area = 10000\n",
        "valor_produto = v_prod[0]\n",
        "valor_micro = v_micro[2]\n",
        "\n",
        "\n",
        "previsao_tree_custo = tree_custo.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Arvore de Decisão na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_tree_custo}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRn3yrGZ7ufJ"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb = GaussianNB()\n",
        "nb = nb.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo de Naive Bayes - GaussianNB\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", nb.score(X_train, y_train))\n",
        "tp_nb = nb.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_nb))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_nb))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(nb, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_nb)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56DcpeQN82lB"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxsXKrUc9WIw"
      },
      "outputs": [],
      "source": [
        "# Naive Bayes\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "\n",
        "previsao_nb = nb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Naive Bayes na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_nb}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qlWGxay7uiH"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando Gradiente Descendente\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "sgd = SGDClassifier()\n",
        "sgd = sgd.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo Gradiente Descendente - SGDClassifier\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", sgd.score(X_train, y_train))\n",
        "tp_sgd = sgd.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_sgd))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_sgd))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(sgd, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_sgd)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohUd_UXp83Wa"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTslXmE19YUt"
      },
      "outputs": [],
      "source": [
        "# Gradiente Descendente\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "previsao_sgd = sgd.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Gradiente Descendente na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_sgd}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAMNMXq27ukr"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando KNN (K - Nearest Neighbors)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn = knn.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo KNN (K - Nearest Neighbors) - KNeighborsClassifier\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", knn.score(X_train, y_train))\n",
        "tp_knn = knn.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_knn))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_knn))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(knn, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_knn)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zan-bc_e84IC"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7TDiuZG9aC_"
      },
      "outputs": [],
      "source": [
        "# KNN (K - Nearest Neighbors)\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "previsao_knn = knn.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para K - Nearest Neighbors na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_knn}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNZFc1fh7unT"
      },
      "outputs": [],
      "source": [
        "#Criação do modelo utilizando Randon Forest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfm = RandomForestClassifier()\n",
        "rfm = rfm.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo Randon Forest - RandomForestClassifier\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", rfm.score(X_train, y_train))\n",
        "tp_rfm = rfm.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_rfm))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_rfm))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(rfm, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_rfm)\n",
        "cnf_table = pd.DataFrame(data = cnf_matrix, index = data_ma['VlCusteio'].unique(), columns = [str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIPUYm5e8440"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYjnuypK9boY"
      },
      "outputs": [],
      "source": [
        "# Random Forest\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "previsao_rfm = rfm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Random Forest na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_rfm}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejrd2cvD8OYx"
      },
      "outputs": [],
      "source": [
        "# Modelo SVC\n",
        "from sklearn.svm import SVC\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo SVC - Support Vector Classification\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", svm.score(X_train, y_train))\n",
        "tp_svm = svm.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_svm))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_svm))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(svm, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_svm)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p37CTfQw85xD"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsRAWsiz9dJY"
      },
      "outputs": [],
      "source": [
        "# SVC (Support Vector Classification)\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "previsao_svm = svm.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio anual para Support Vector Classification na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_svm}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-hbgktu8ObZ"
      },
      "outputs": [],
      "source": [
        "# GradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo GradientBoostingClassifier\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", gb.score(X_train, y_train))\n",
        "tp_gb = gb.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_gb))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_gb))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(gb, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_gb)\n",
        "nf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RcRtjbH086di"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdvsOtRC9e13"
      },
      "outputs": [],
      "source": [
        "# Gradient Boosting Classifier\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "previsao_gb = gb.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Gradient Boosting Classifier na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_gb}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCNAYy7J8Od0"
      },
      "outputs": [],
      "source": [
        "# Modelo AdaBoostClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada = AdaBoostClassifier()\n",
        "ada.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo AdaBoostClassifier\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", ada.score(X_train, y_train))\n",
        "tp_ada = ada.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_ada))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_ada))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(ada, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_ada)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ap9cDyMu87PC"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhdBy6ER9gUY"
      },
      "outputs": [],
      "source": [
        "# AdaBoost Classifier\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "previsao_ada = ada.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para AdaBoost Classifier na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_ada}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALPIbEuk8Ogx"
      },
      "outputs": [],
      "source": [
        "# Modelo ExtraTreesClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "et = ExtraTreesClassifier()\n",
        "et.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo ExtraTreesClassifier\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", et.score(X_train, y_train))\n",
        "tp_et = et.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_et))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_et))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(et, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_et)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5Qpd8fB88Aa"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp4GfT8k9iGF"
      },
      "outputs": [],
      "source": [
        "# Extra Trees Classifier\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "previsao_et = et.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Extra Trees Classifier na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_et}\\n\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyiK90VM7up6"
      },
      "outputs": [],
      "source": [
        "# Regressão Logística\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "print(\"\")\n",
        "print(\"Modelo LogisticRegression\")\n",
        "print(\"\")\n",
        "print(\"Dados de Acurácia\")\n",
        "print(\"Acurácia (base de treinamento): \", lr.score(X_train, y_train))\n",
        "tp_lr = lr.predict(X_test)\n",
        "print(\"Acurácia de previsão: \", accuracy_score(y_test, tp_lr))\n",
        "print(\"\")\n",
        "print(\"Classification Report:\")\n",
        "print(\"\")\n",
        "print(classification_report(y_test, tp_lr))\n",
        "print(\"\")\n",
        "print(\"Validação Cruzada:\")\n",
        "print(\"\")\n",
        "scores = cross_val_score(lr, X, y, cv=5)\n",
        "score = scores.sum()/5\n",
        "print(\"Cross-validation: \",scores)\n",
        "print(\"Média cross-validation: \", score)\n",
        "print(\"\")\n",
        "print(\"Matriz de Confusão:\")\n",
        "print(\"\")\n",
        "cnf_matrix = confusion_matrix(y_test, tp_lr)\n",
        "cnf_table = pd.DataFrame(data=cnf_matrix, index=data_ma['VlCusteio'].unique(), columns=[str(x) + '_prev' for x in data_ma['VlCusteio'].unique()])\n",
        "print(cnf_table)\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtiLWn4M882c"
      },
      "outputs": [],
      "source": [
        "# Plotar mapa de calor\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cnf_table, annot=True, cmap=\"YlGnBu\")\n",
        "plt.xlabel('Valor Previsto')\n",
        "plt.ylabel('Valor Real')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Lc3xmLT9j14"
      },
      "outputs": [],
      "source": [
        "# Regressão Logística\n",
        "\n",
        "v_prod = selecionados\n",
        "v_micro = micro\n",
        "valores_para_previsao = [[4000,1,0,0,1,0,0,0,0,0]]\n",
        "valor_area = 4000\n",
        "valor_produto = v_prod[1]\n",
        "valor_micro = v_micro[1]\n",
        "\n",
        "previsao_lr = lr.predict(valores_para_previsao)\n",
        "print(f'Previsão de faixa de custeio trimestral para Regressão Logística na mesorregião Triângulo Mineiro / Alto Paranaíba, microrregião {valor_micro} produto {valor_produto} e área de {valor_area} km²: {previsao_lr}\\n\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "coaeK6607usk"
      },
      "outputs": [],
      "source": [
        "# Armazena os resultados em um dicionário\n",
        "resultados = {\n",
        "    'Árvore de Decisão': {\n",
        "        'Acurácia Treinamento': [tree_custo.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, y_pred)],\n",
        "        'Cross-Validation': [cross_val_score(tree_custo, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'Naive Bayes': {\n",
        "        'Acurácia Treinamento': [nb.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_nb)],\n",
        "        'Cross-Validation': [cross_val_score(nb, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'Gradiente Descendente': {\n",
        "        'Acurácia Treinamento': [sgd.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_sgd)],\n",
        "        'Cross-Validation': [cross_val_score(sgd, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'KNN': {\n",
        "        'Acurácia Treinamento': [knn.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_knn)],\n",
        "        'Cross-Validation': [cross_val_score(knn, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'Acurácia Treinamento': [rfm.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_rfm)],\n",
        "        'Cross-Validation': [cross_val_score(rfm, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'SVC': {\n",
        "        'Acurácia Treinamento': [svm.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_svm)],\n",
        "        'Cross-Validation': [cross_val_score(svm, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'GradientBoostingClassifier': {\n",
        "        'Acurácia Treinamento': [gb.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_gb)],\n",
        "        'Cross-Validation': [cross_val_score(gb, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'AdaBoostClassifier': {\n",
        "        'Acurácia Treinamento': [ada.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_ada)],\n",
        "        'Cross-Validation': [cross_val_score(ada, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'ExtraTreesClassifier': {\n",
        "        'Acurácia Treinamento': [et.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_et)],\n",
        "        'Cross-Validation': [cross_val_score(et, X, y, cv=5).mean()]\n",
        "    },\n",
        "    'Regressão Logística': {\n",
        "        'Acurácia Treinamento': [lr.score(X_train, y_train)],\n",
        "        'Acurácia Teste': [accuracy_score(y_test, tp_lr)],\n",
        "        'Cross-Validation': [cross_val_score(lr, X, y, cv=5).mean()]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Criar e exibir as tabelas de resultados\n",
        "for modelo, resultados_mesorregiao in resultados.items():\n",
        "    df_resultados = pd.DataFrame(resultados_mesorregiao)\n",
        "    df_resultados.index.name = None\n",
        "    print(f\"Resultados do Modelo: {modelo}\\n\")\n",
        "    print(df_resultados)\n",
        "    print('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6zlVnUd7uvz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEfHKyi1Dn8Q"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbubS/xV/PF9XZCwg4UhPe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
